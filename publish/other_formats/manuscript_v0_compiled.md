---
title: 'Closed-Loop Identifiability in Neural Circuits'
output:
    pdf_document: {path: /publish/manuscript_pandoc.pdf}
xnumbersections: true
author:
    - {name: 'Adam Willats, Matthew O''Shaughnessy'}
---  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#  Abstract
  
  
!!!! Todo 3/16: - Mention basic science applications of CL control - Maybe more forecasting idea of shaping correlations? (don't want reader to be surprised by structure of paper's argument)
  
  
The necessity of intervention in inferring cause has long been understood in neuroscience. Recent work has highlighted the limitations of passive observation and single-site lesion studies in accurately recovering causal circuit structure. The advent of optogenetics has facilitated increasingly precise forms of intervention including closed-loop control which may help eliminate confounding influences. However, it is not yet clear how best to apply closed-loop control to leverage this increased inferential power. In this paper, we use tools from causal inference, control theory, and neuroscience to show when and how closed-loop interventions can more effectively reveal causal relationships. `We also examine the performance of standard network inference procedures in simulated spiking networks under passive, open-loop and closed-loop conditions.` We demonstrate a unique capacity of feedback control to distinguish competing circuit hypotheses by disrupting connections which would otherwise result in equivalent patterns of correlation[^bidir]. Our results build toward a practical framework to improve design of neuroscience experiments to answer causal questions about neural circuits.
  
[^bidir]: may end up discussing quantitative advantages such as bidirectional variance (and correlation) control. If that's a strong focus in the results, should be talked about more in the abstract also
  
  
  
#  Introduction
  
  
##  Estimating causal interactions in the brain
  
  
!!!! - 70% done
  
!!!! Todo 3/16: - "We first propose..." paragraph (could build out or move or change focus away from the 'framework') - think about condensing and/or moving "Inferring causal interactions from time series" subsection - Maybe add half a paragraph or so in the discussion about how causal inference tools can help above correlation analysis (e.g., PC algorithm)
  
  
Many hypotheses about neural circuits are phrased in terms of causal relationships: "will changes in activity to this region of the brain produce corresponding changes in another region?" Understanding these causal relationships is critical to both scientific understanding and to developing effective therapeutic interventions, which require knowledge of how potential therapies will impact brain activity and patient outcomes.
  
A range of mathematical and practical challenges make it difficult to determine these causal relationships. In studies that rely only observational data, it is often impossible to determine whether observed patterns of activity are caused by known and controlled inputs, or whether they are instead spurious connections generated by recurrent activity, indirect relationships, or unobserved "confounders." It is generally understood that moving from experiments involving passive observation to more complex levels of intervention allows experimenters to better tackle challenges to circuit identification. However, while chemical and surgical lesion experiments have historically been employed to remove the influence of possible confounds, they are likely to dramatically disrupt circuits from their typical functions, making conclusions about underlying causal structure drawn from these experiments unlikely to hold in naturalistic settings \cite{chicharro2012when}. *Closed-loop* interventions ==...@Adam: short description of closed-loop in neuro, maybe drawing from text in this collapsable:==
  
<details><summary>Proposal text to draw from:</summary>
  
For decades, engineers have used feedback control to actuate a system based on measured activity to reduce variability, compensate for imperfect measurements, drive systems to desired set points, and decouple connected systems [...]
  
There is an increasing interest in using approaches from closed-loop control for neural stimulation to both study complex neural circuits and treat neurologic disorders. Recently, a growing community is developing and applying closed-loop stimulation strategies at the cellular and circuit level (Miranda-Dominguez, Gonia, and Netoff 2010; Santaniello, Burns, et al. 2011; Ching et al. 2013; Iolov, Ditlevsen, and Longtin 2014; Nandi, Kafashan, and Ching 2016; Bolus et al. 2018) to understand the brain (Packer et al. 2015) as well as treat disorders (Santaniello, Fiengo, et al. 2011; Paz et al. 2013; Ehrens, Sritharan, and Sarma 2015; Choi et al. 2016; Yang and Shanechi 2016; KozÃ¡k and BerÃ©nyi 2017; Sorokin et al. 2017) The advent of optogenetic stimulation has accelerated the potential for effective closed-loop stimulation by providing actuation strategies that can be more precisely targeted and have minimal recording artifacts compared to conventional microelectrode stimulation (Grosenick, Marshel, and Deisseroth 2015)
  
Most applications of closed-loop control to neuroscience to date have used â€œactivity-guided / responsive / triggered stimulationâ€ wherein a predesigned stimulus is delivered in response to a detected event. For example, in (Krook-Magnuson et al. 2013) the authors detect seizure activity from spiking and local field potential features to trigger a pulse-train of inhibitory optogenetic stimulation which interrupts the seizure. While this is an effective approach for many applications, these types of closed-loop experiments should be distinguished from closed-loop with ongoing feedback such as dynamic clamp. In these feedback control approaches parameters of stimulation are adjusted on much faster timescales in response to measured activity. For dynamic clamp experiments, this low-latency ongoing feedback control allows experimenters to deliver currents which mimic virtual ion channels which would be implausible with triggered predesigned stimulation. These approaches provide additional precision in being able to drive activity patterns, but also come with increased algorithmic and hardware demands. For the rest of this document, we will use â€œclosed-loop controlâ€ or â€œfeedback controlâ€ to refer to this second, more specific class of approaches.
  
While many such new actuation and measurement tools have recently become available for neural systems, we require the development of principled algorithmic tools for designing feedback controllers to use these neural interfaces. Our collaborators have previously demonstrated successful closed-loop optogenetic control (CLOC) in-vitro (Newman et al. 2015) and in-vivo (Bolus et al. 2018) to track naturalistic, time-varying trajectories of firing rate.
  
-> Also add citation to \cite{ramot2022closedloop}
  
</details>
  
Despite the promise of these closed-loop strategies for identifying causal relations in neural circuits, however, it is not yet fully understood *when* more complex intervention strategies can provide additional inferential power, or *how* these experiments should be optimally designed. In this paper we demonstrate when and how closed-loop interventions can reveal the causal structure governing neural circuits. Drawing from ideas in causal inference [@pearl2009causality] \cite{maathuis2016review} \cite{chis2011structural}, we describe the classes of models that can be distinguished by a given set of input-output experiments, and what experiments are necessary to uniquely determine specific causal relationships.
  
We first propose a mathematical framework that describes how open- and closed-loop interventions impact observable qualities of neural circuits. Using this framework, experimentalists propose a set of candidate hypotheses describing the potential causal structure of the circuit under study, and then select a series of interventions that best allows them to distinguish between these hypotheses. Using both simple controlled models and in silico models of spiking networks, we explore factors that govern the efficacy of these types of interventions. Guided by the results of this exploration, we present a set of recommendations that can guide the design of open- and closed-loop experiments to better uncover the causal structure underlying neural circuits.
  
**Inferring causal interactions from time series.** A number of strategies have been proposed to detect causal relationships between observed variables. Wiener-Granger (or predictive) causality states that a variable <img src="https://latex.codecogs.com/gif.latex?X"/> "Granger-causes" <img src="https://latex.codecogs.com/gif.latex?Y"/> if <img src="https://latex.codecogs.com/gif.latex?X"/> contains information relevant to <img src="https://latex.codecogs.com/gif.latex?Y"/> that is not contained in <img src="https://latex.codecogs.com/gif.latex?Y"/> itself or any other variable \cite{wiener1956theory}. This concept has traditionally been operationalized with vector autoregressive models \cite{granger1969investigating}; the requirement that *all* potentially causative variables be considered makes these notions of dependence susceptible to unobserved confounders \cite{runge2018causal}.
  
Our work initially focuses on measures of directional interaction that are based on lagged correlations \cite{melssen1987detection}. These metrics look at the correlation of time series collected from pairs of nodes at various lags and detect peaks at negative time lags. Such peaks could indicate the presence of a direct causal relationship -- but they could also stem from indirect causal links or hidden confounders \cite{dean2016dangers}. In these bivariate correlation methods, it is thus necessary to consider patterns of correlation between many pairs of nodes in order to differentiate between direct, indirect, and confounding relationships \cite{dean2016dangers}. This distinguishes these strategies from some multivariate methods that "control" for the effects of potential confounders. While cross-correlation-based measures are generally limited to detecting linear functional relationships between nodes, their computational feasibility makes them a frequent metric of choice in experimental neuroscience work \cite{knox1981detection} \cite{salinas2001correlated} \cite{garofalo2009evaluation}.
  
Other techniques detect directional interaction stemming from more general or complex relationships. Information-theoretic methods, which use information-based measures to assess the reduction in entropy knowledge of one variable provides about another, are closely related to Granger causality \cite{schreiber2000measuring} \cite{barnett2009granger}. The *transfer entropy* <img src="https://latex.codecogs.com/gif.latex?T_{X%20&#x5C;to%20Y}(t)%20=%20I(Y_t%20&#x5C;colon%20X_{&lt;t}%20&#x5C;mid%20Y_{&lt;t})"/> extends this notion to time series by measuring the amount of information present in <img src="https://latex.codecogs.com/gif.latex?Y_t"/> that is not contained in the past of either <img src="https://latex.codecogs.com/gif.latex?X"/> or <img src="https://latex.codecogs.com/gif.latex?Y"/> (denoted <img src="https://latex.codecogs.com/gif.latex?X_{&lt;t}"/> and <img src="https://latex.codecogs.com/gif.latex?Y_{&lt;t}"/>) \cite{bossomaier2016transfer}. Using transfer entropy as a measure of causal interaction requires accounting for potential confounding variables; the *conditional transfer entropy* <img src="https://latex.codecogs.com/gif.latex?T_{X%20&#x5C;to%20Y%20&#x5C;mid%20Z}(t)%20=%20I(Y_t%20&#x5C;colon%20X_{&lt;t}%20&#x5C;mid%20Y_{&lt;t},%20Z_{&lt;t})"/> conditions on the past of other variables to account for their potential confounding influence \cite[Sec.~4.2.3]{bossomaier2016transfer}. Conditional transfer entropy can thus be interpreted as the amount of information present in <img src="https://latex.codecogs.com/gif.latex?Y"/> that is not contained in the past of <img src="https://latex.codecogs.com/gif.latex?X"/>, the past of <img src="https://latex.codecogs.com/gif.latex?Y"/>, or the past of other variables <img src="https://latex.codecogs.com/gif.latex?Z"/>.
  
To quantify the strength of causal interactions, information-theoretic and transfer-entropy-based methods typically require knowledge of the ground truth causal relationships that exist \cite{janzing2013quantifying} or an ability to perturb the system \cite{ay2008information} \cite{lizier2010differentiating}. In practice, these quantities are typically interpreted as "information transfer," and a variety of estimation strategies and methods to automatically select the conditioning set (i.e., the variables and time lags that should be conditioned on) are used (e.g., \cite{shorten2021estimating}). Multivariate conditional transfer entropy approaches using various variable selection schemes can differentiate between direct interactions, indirect interactions, and common causes, but their results depend on choices such as the binning strategies used to discretize continuous signals, the specific statistical tests used, and the estimator used to compute transfer entropy \cite{wibral2014directed}. `[If we end up making the jump to IDTxl in our results: In our empirical results using transfer-entropy-based notions of directional influence we use the IDTxl toolbox \cite{wollstadt2019idtxl}.]` However, despite their mathematical differences, previous work has found that cross-correlation-based metrics and information-based metrics tend to produce qualitatively similar results, with similar patterns of true and false positives \cite{garofalo2009evaluation}.
  
  
##  Interventions in neuroscience & causal inference
  
  
!!!! - 70% done
  
!!!! Todo - Get language more precise and effective *(see writing_tasks)*
  
  
Data collected from experimental settings can be much more powerful than observational data alone. For example, passive observations of two correlated variables <img src="https://latex.codecogs.com/gif.latex?x"/> and <img src="https://latex.codecogs.com/gif.latex?y"/> do not allow a scientist to determine whether <img src="https://latex.codecogs.com/gif.latex?x"/> is driving <img src="https://latex.codecogs.com/gif.latex?y"/>, <img src="https://latex.codecogs.com/gif.latex?y"/> is driving <img src="https://latex.codecogs.com/gif.latex?x"/>, or if the two variables are being independently driven by a hidden confounder. Experimentally manipulating <img src="https://latex.codecogs.com/gif.latex?x"/> and observing the output of <img src="https://latex.codecogs.com/gif.latex?y"/>, however, allows the scientist to begin to establish which potential causal interaction pattern is at work. Consistent with intuition from neuroscience literature, a rich theoretical literature has described the central role of interventions in inferring causal structure from data \cite{pearl2009causality, eberhardt2007interventions}.
  
![](figures/core_figure_sketches/figure1_sketch.png "")
> **Figure INTRO:** Examples of the roles interventions have played in neuroscience. (A) *Passive observation* does not involve stimulating the brain. In this example, passive observational data is used to identify patients suffering from absence seizures. (B) *Open-loop stimulation* involves recording activity in the brain after perturbing a region with a known input signal. Using systematic *open-loop stimulation experiments*, Penfield uncovered the spatial organization of how senses and movement are mapped in the cortex \cite{penfield1937somatic} \cite{penfield1950cerebral}. (C) *Closed-loop control* uses feedback control to precisely specify activity in certain brain regions regardless of activity in other regions. Using closed-loop control, ==todo-Adam== \cite{==todo-Adam==}.
  
The inferential power of interventions is depends on *where* stimulation is applied: interventions on some portions of a system may provide more information about the system's causal structure than interventions in other areas. And interventions are also more valuable when they more effectively set the state of the system: "perfect" closed-loop control, which completely severs a node's activity from its inputs, are often more informative than "soft" interventions that only partially control a part of the system \cite{eberhardt2007interventions}.
  
In experimental neuroscience settings, experimenters are faced with deciding between interventions that differ in both location and effectiveness. For example, stimulation can often only be applied to certain regions of the brain. And while experimenters may be able to exactly manipulate activity in some parts of the brain using closed-loop control, in other locations it may only be possible to apply weaker forms of intervention that perturb a region but do not manipulate its activity exactly to a desired state. In Section [X], we compare the effectiveness of open-loop, closed-loop, and partially-effective closed-loop control.
  
Theoretical guarantees for the strength of these interventions -- and algorithms designed to choose among them -- are often designed for simple models with strong assumptions.[^more] However, they provide guidance that can that can help practitioners design experiments that provide as much scientific insight as possible.[^possible-cite] Importantly, power of interventions is often independent of the algorithm used to infer causal connections, meaning that certain interventions can reveal portions of a circuit's causal structure that would be impossible for *any* algorithm to infer from only observational data (see, e.g., \cite{shanmugam2015learning}).
  
[^more]: These assumptions are typically on properties such as the types of functional relationships that exist in circuits, the visibility and structure of confounding relationships, and noise statistics.
  
[^possible-cite]: if citations needed here, could start by looking for a good high-level reference in either \cite{ghassami2018budgeted} or \cite{yang2018characterizing}. (Both of these papers are pretty technical, so likely wouln't be great citations on their own.)
  
  
##  Representations & reachability
  
  
!!!! - 60% done
  
!!!! todo - Rewrite X=XW+E as vector version - Describe what 'reachability' is *(see writing_tasks)*
  
  
[^exog]: the most important property of <img src="https://latex.codecogs.com/gif.latex?e"/> for the math to work, i believe, is that they're random variables independent of each other. This is not true in general if E is capturing input from common sources, other nodes in the network. I think to solve this, we'll need to have an endogenous independent noise term and an externally applied (potentially common) stimulus term.
[^sim_repr]: have to be careful with this. this almost looks like a dynamical system, but isn't. In simulation we're doing something like an SCM, where the circuit is sorted topologically then computed sequentially. have to resolve / compare these implementations
  
Different mathematical representations of circuits can elucidate different connectivity properties. For example, consider the circuit <img src="https://latex.codecogs.com/gif.latex?A%20&#x5C;rightarrow%20B%20&#x5C;leftarrow%20C"/>. This circuit can be modeled by the dynamical system
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{cases}&#x5C;dot{x}_A%20&amp;=%20f_A(e_A)%20&#x5C;&#x5C;&#x5C;dot{x}_B%20&amp;=%20f_B(x_A,%20x_C,%20e_B)%20&#x5C;&#x5C;&#x5C;dot{x}_C%20&amp;=%20f_C(e_C),&#x5C;end{cases}"/></p>  
  
where <img src="https://latex.codecogs.com/gif.latex?e_A"/>, <img src="https://latex.codecogs.com/gif.latex?e_B"/>, and <img src="https://latex.codecogs.com/gif.latex?e_C"/> represent exogenous inputs that are inputs from other variables and each other[^exog].
  
When the system is linear we can use matrix notation to denote the impact of each node on the others. Denote the <img src="https://latex.codecogs.com/gif.latex?p%20&#x5C;times%20n"/> matrix of data samples by <img src="https://latex.codecogs.com/gif.latex?X"/> and the <img src="https://latex.codecogs.com/gif.latex?p%20&#x5C;times%20n"/> matrix of exogenous input values by <img src="https://latex.codecogs.com/gif.latex?E"/>. We can then write[^sim_repr]
<p align="center"><img src="https://latex.codecogs.com/gif.latex?X%20=%20X%20W%20+%20E,"/></p>  
  
  
!!!! - TODO Adam, write out the dynamical system version of this 
  
  
  
where <img src="https://latex.codecogs.com/gif.latex?W"/> represents the *adjacency matrix*
<p align="center"><img src="https://latex.codecogs.com/gif.latex?W%20=%20&#x5C;begin{bmatrix}%20%20%20%20w_{AA}%20&amp;%20w_{AB}%20&amp;%20w_{AC}%20&#x5C;&#x5C;%20%20%20%20w_{BA}%20&amp;%20w_{BB}%20&amp;%20w_{BC}%20&#x5C;&#x5C;%20%20%20%20w_{CA}%20&amp;%20w_{CB}%20&amp;%20w_{CC}&#x5C;end{bmatrix}."/></p>  
  
In the circuit <img src="https://latex.codecogs.com/gif.latex?A%20&#x5C;rightarrow%20B%20&#x5C;leftarrow%20C"/>, we would have <img src="https://latex.codecogs.com/gif.latex?w_{AB}%20&#x5C;neq%200"/> and <img src="https://latex.codecogs.com/gif.latex?w_{CB}%20&#x5C;neq%200"/>.
  
The adjacency matrix captures directional first-order connections in the circuit: <img src="https://latex.codecogs.com/gif.latex?w_{ij}"/>, for example, describes how activity in <img src="https://latex.codecogs.com/gif.latex?x_j"/> changes in response to activity in <img src="https://latex.codecogs.com/gif.latex?x_i"/>.
  
Our goal is to reason about the relationship between underlying causal structure (which we want to understand) and the correlation or information shared by pairs of nodes in the circuit (which we can observe). Quantities based on the  adjacency matrix and weighted reachability matrix bridge this gap, connecting the causal structure of a circuit to the correlation structure its nodes will produce.
  
The directional <img src="https://latex.codecogs.com/gif.latex?k^{&#x5C;mathrm{th}}"/>-order connections in the circuit are similarly described by the matrix <img src="https://latex.codecogs.com/gif.latex?W^k"/>, so the *weighted reachability matrix*
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}%20=%20&#x5C;sum_{k=0}^{&#x5C;infty}%20W^k"/></p>  
  
describes the total impact --- through both first-order (direct) connections and higher-order (indirect) connections --- of each node on the others. Whether node <img src="https://latex.codecogs.com/gif.latex?j"/> is "reachable" (Skiena 2011) from node <img src="https://latex.codecogs.com/gif.latex?i"/> by a direct or indirect connection is thus indicated by <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{ij}%20&#x5C;neq%200"/>, with the magnitude of <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{ij}"/> indicating sensitive node <img src="https://latex.codecogs.com/gif.latex?j"/> is to a change in node <img src="https://latex.codecogs.com/gif.latex?i"/>.
  
This notion of reachability, encoded by the pattern of nonzero entries in <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}"/>, allows us to determine when two nodes will be correlated (or more generally, contain information about each other). Moreover, as we will describe in Sections [REF] and [REF], quantities derived from these representations can also be used to describe the impact of open- and closed-loop interventions on circuit behavior, allowing us to quantitatively explore the impact of these interventions on the identifiability of circuits.
  
`[Matt to Adam --- I like the idea of an example here, but the details will likely need to change once the neighboring intro sections take shape]`
  
!!!! - transition from reachability to 2-circuit ID demo is now in [background_id_demo.md](background_id_demo.md )
  
<details><summary>â†ªold reachability â†’ ID demo text </summary>
  
Consider, for example, the hypotheses for cortical gain control in open-loop (Figure BACKGROUND>REPRESENTATION/REACH-1, left column). In both circuit 2a and 2b, PV cells are reachable from the Som cell node (<img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{PV%20&#x5C;to%20Som}%20&#x5C;neq%200"/>), since Som activity can influence PV activity indirectly through the Pyr node. These circuits are therefore difficult to distinguish under open-loop intervention.
  
If the reachability of two circuits are unequal for a given intervention, differences in correlation between observed regions will be sufficient to distinguish between the two hypotheses. Looking at these same circuits under closed-loop control of the pyramidal population (Figure BACKGROUND>REPRESENTATION/REACH-1, right column), dashed lines reveal that there is no longer an indirect functional connection from Som to PV cells. As such, in circuit 2a, PV cells are no longer reachable from the Som population, whereas they are reachable under circuit 2b. This difference in reachability corresponds to the difference in correlational structure that allows us to distinguish these two hypotheses under closed-loop control.
  
![](figures/misc_figure_sketches/closed_loop_distinguishes_corticalEI.png )
**Figure BACKGROUND>REPRESENTATION/REACH-1: Closed-loop control allows for two circuit hypotheses to be distinguished.** Two hypothesized circuits for the relationships between pyramidal (Pyr, excitatory), parvalbumin-positive (PV, inhibitory), and somatostain-expressing (Som, inhibitory) cells are shown in the two rows. Dashed lines in the right column represent connections whose effects are compensated for through closed-loop control of the Pyr node. By measuring correlations between recorded regions during closed-loop control it is possible to distinguish which hypothesized circuit better matches the data. Notably in the open-loop intervention, activity in all regions is correlated for both hypothesized circuits leading to ambiguity.
  
</details>
  
  
  
  
  
  
!!!! - 70% done
  
!!!! todo - Talk about what 'reachability' means (total direct+indirect impact) - [Matt:] Rewrite first paragraph to not use notation (place this box before any theory/notation sections) - [Matt:] Set expectation here that we're talking about linear Gaussian circuits
  
  
![](figures/core_figure_sketches/circuit_walkthrough_3circuits_key_sketch.png "generated by /code/fig_circuit_walkthrough.py")
> **Figure DEMO _(box format)_: Applying CLINC to distinguish a pair of circuits**
>
> Consider the three-node identification problem shown in the figure above, in which the experimenter has identified three hypotheses for the causal structure of the circuit. These circuit hypotheses, shown as directed graphs in column 1, can each also be represented by an adjacency matrix of the form \ref{eq:adjacency-matrix}: for example, circuit A is represented by an adjacency matrix in which <img src="https://latex.codecogs.com/gif.latex?w_{01}"/>, <img src="https://latex.codecogs.com/gif.latex?w_{20}"/>, and <img src="https://latex.codecogs.com/gif.latex?w_{21}%20&#x5C;neq%200"/>. Note that hypotheses A and C have direct connections between nodes 0 and 2; while hypothesis B does not have a direct connection between these nodes, computing the weighted reachability matrix <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}"/> in circuit B an *indirect* connection exists through the path 2 <img src="https://latex.codecogs.com/gif.latex?&#x5C;to"/> 1 <img src="https://latex.codecogs.com/gif.latex?&#x5C;to"/> 0 (illustrated in gray in column 2).
>
> Because there are direct or indirect connections between each pair of nodes, passive observation of each hypothesized circuit would reveal that each pair of nodes is correlated (column 3). These three hypotheses are therefore difficult to distinguish[^a] for an experimentalist who performs only passive observation, but can be distinguished through stimulation.
>
> Column 4 shows the impact on observed correlations of performing *open-loop* control on node 1. In hypothesis A, node 1 is not a driver of other nodes, so open-loop stimulation at this site will not increase the correlation between the signal observed at node 1 and other nodes. The path from node 1 to 0 in hypotheses B and C, meanwhile, causes the open-loop stimulation at node 1 to *increase* the observed correlation between nodes 1 and 0. An experimenter can thus distinguish between hypothesis A and the other two hypotheses by appling open-loop control and observing the resulting pattern of correlations (column 4). However, this pattern of open-loop stimulation would not allow the experimenter to distinguish between hypotheses B and C.
>
> *Closed-loop* control (columns 5 and 6) can provide the experimenter with even more inferential power. Column 5 shows the resulting adjacency matrix when this closed-loop control is applied to node 1. In each hypothesis, the impact of this closed-loop control is to remove the impact of other nodes on node 1, because when perfect closed-loop is applied the activity of node 1 is completely independent of other nodes. (These severed connections are depicted in column 5 by dashed lines.) In hypothesis B, this also results in the elimation of the indirect connection from node 2 to node 1. The application of closed-loop control at node 1 thus results in a different observed correlation structure in each of the three circuit hypotheses (column 6). This means that the experimenter can therefore distinguish between these circuit hypotheses by applying closed-loop control -- a task not possible with passive observation or open-loop control.
  
<details><summary>â†ª figure to do items for @Adam</summary>
  
- [ ] @Adam - change labels at top from "B" to "1"
- [ ] @Adam - add (A) (B) (C) labels to each row
- [ ] @Adam - in legend, change in/direct "edge" to in/direct "connection"
- [ ] @Adam - in legend, orange dashed arrow to dark gray
  
</details>
  
[^a]: saying "difficult to distinguish" instead of "indistinguishable" here since the magnitudes of the correlations could also be informative with different assumptions
  
---
<details><summary>â†ª2,3 circuit versions, straight from code</summary>
  
![](code/network_analysis/results/circuit_walkthrough_2circuits.png "generated by /code/fig_circuit_walkthrough.py")
![](code/network_analysis/results/circuit_walkthrough_3circuits.png "generated by /code/fig_circuit_walkthrough.py")
> 3 circuit walkthrough, walkthrough will all intervention locations might be appropriate for the supplement
  
</details>
  
  
<details><summary>â†ªto do items</summary>
  
- [ ] find and include frequent circuit (curto + motif)
- [ ] wrap circuits we want in `example_circuits.py`
- [ ] alt method of displaying indirect paths?
  - https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.simple_paths.all_simple_paths.html#networkx.algorithms.simple_paths.all_simple_paths
</details>
  
<details><summary> â†ªsee also</summary>
  
more inspiration:
- Combining multiple functional connectivity methods to improve causal inferences
- Advancing functional connectivity research from association to causation
- Fig1. of "Systematic errors in connectivity"
  
![](code/network_analysis/results/effect_of_control_horiz.png )
![](figures/misc_figure_sketches/two_circuit_case_study_mockup.png )
  
> this figure does a great job of:
> - setting up a key
> - incrementally adding confounds
> - highlighting severed edges
> this figure does NOT
> - explicitly address mutliple hypotheses
  
![](figures/misc_figure_sketches/closed_loop_severs_inputs.png )
**Figure 11: Closed-loop control compensates for inputs to a node in simple circuits:** The left column shows a simple circuit and recording and stimulation sites for an open-loop experiment. The right column shows the functional circuit which results from closed-loop control of the output of region A. Generally, assuming perfectly effective control, the impact of other inputs to a controlled node is nullified and therefore crossed off the functional circuit diagram.
  
> this figure does a great job of:
> - using a minimal version of the key above
> - showing two competing hypotheses
> - (throughs latent / common modulation in for fun)
  
![](figures/misc_figure_sketches/closed_loop_distinguishes_corticalEI.png )
**Figure 12: Closed-loop control allows for two circuit hypotheses to be distinguished.** Two hypothesized circuits for the relationships between pyramidal (Pyr, excitatory), parvalbumin-positive (PV, inhibitory), and somatostain-expressing (Som, inhibitory) cells are shown in the two rows. Dashed lines in the right column represent connections whose effects are compensated for through closed-loop control of the Pyr node. By measuring correlations between recorded regions during closed-loop control it is possible to distinguish which hypothesized circuit better matches the data. Notably in the open-loop intervention, activity in all regions is correlated for both hypothesized circuits leading to ambiguity.
</details>
  
<details><summary>â†ªmore notes</summary>
  
probably want
- two circuits which look clearly different
  - ! but which have equivalent reachability
  - possibly with reciprocal connections
  - possssibly with common modulation
  
- do we need to reflect back from set of possible observations to consistent hypotheses?
  - mention markov equivalence classes explicitly?
  
- intuitive explanation using binary reachability rules
  <!-- - consider postponing until we introduce intervention?
  - i.e. have one figure that walks through both reachability and impact of intervention -->
- *point to the rest of the paper as deepening and generalizing these ideas*
- *(example papers - Advancing functional connectivity research from association to causation, Combining multiple functional connectivity methods to improve causal inferences)*
  
- connect **graded reachability** to ID-SNR
  - <img src="https://latex.codecogs.com/gif.latex?&#x5C;mathrm{IDSNR}_{ij}"/> measures the strength of signal related to the connection <img src="https://latex.codecogs.com/gif.latex?iâ†’j"/> relative to in the output of node <img src="https://latex.codecogs.com/gif.latex?j"/>
  - for true, direct connections this quantity increasing means a (true positive) connection will be identified more easily (with high certainty, requiring less data)
  - for false or indirect connections, this quantity increasing means a false positive connection is more likely to be identified
  - as a result we want to maximize IDSNR for true links, and minimize it for false/indirect links
  
  
( see also `sketches_and_notation/walkthrough_EI_dissection.md` )
  
  
</details>
  
  
  
#  Theory / Prediction
  
  
  
![](figures/core_figure_sketches/methods_overview_pipeline_sketch.png )
> **Figure OVERVIEW:** ...
  
  
  
##  Predicting correlation structure (theory)
  
  
  
A linear-Gaussian circuit can be described by 1) the variance of the Gaussian private (independent) noise at each node, and 2) the weight of the linear relationships between each pair of connected nodes. Let <img src="https://latex.codecogs.com/gif.latex?s%20&#x5C;in%20&#x5C;mathbb{R}^p"/> denote the variance of each of the <img src="https://latex.codecogs.com/gif.latex?p"/> nodes in the circuit, and <img src="https://latex.codecogs.com/gif.latex?W%20&#x5C;in%20&#x5C;mathbb{R}^{p%20&#x5C;times%20p}"/> denote the matrix of connection strengths such that <p align="center"><img src="https://latex.codecogs.com/gif.latex?W_{ij}%20=%20&#x5C;text{strength%20of%20<img src="https://latex.codecogs.com/gif.latex?i%20&amp;#x5C;to%20j"/>%20connection}."/></p>  
  
  
Note that <img src="https://latex.codecogs.com/gif.latex?&#x5C;left[(W^T)%20s&#x5C;right]_j"/> gives the variance at node <img src="https://latex.codecogs.com/gif.latex?j"/> due to length-1 (direct) connections, and more generally, <img src="https://latex.codecogs.com/gif.latex?&#x5C;left[%20(W^T)^k%20s%20&#x5C;right]_j"/> gives the variance at node <img src="https://latex.codecogs.com/gif.latex?j"/> due to length-<img src="https://latex.codecogs.com/gif.latex?k"/> (indirect) connections. The *total* variance at node <img src="https://latex.codecogs.com/gif.latex?j"/> is thus <img src="https://latex.codecogs.com/gif.latex?&#x5C;left[%20&#x5C;sum_{k=0}^{&#x5C;infty}%20(W^T)^k%20s%20&#x5C;right]_j"/>.
  
Our goal is to connect private variances and connection strengths to observed pairwise correlations in the circuit. Defining <img src="https://latex.codecogs.com/gif.latex?X%20&#x5C;in%20&#x5C;mathbb{R}^{p%20&#x5C;times%20n}"/> as the matrix of <img src="https://latex.codecogs.com/gif.latex?n"/> observations of each node, we have[^covariance-derivation]
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{aligned}%20%20%20%20&#x5C;Sigma%20&amp;=%20&#x5C;mathrm{cov}(X)%20=%20&#x5C;mathbb{E}&#x5C;left[X%20X^T&#x5C;right]%20&#x5C;&#x5C;%20%20%20%20&amp;=%20(I-W^T)^{-1}%20&#x5C;mathrm{diag}(s)%20(I-W^T)^{-T}%20&#x5C;&#x5C;%20%20%20%20&amp;=%20&#x5C;widetilde{W}%20&#x5C;mathrm{diag}(s)%20&#x5C;widetilde{W}^T,&#x5C;end{aligned}"/></p>  
  
where <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}%20=%20&#x5C;sum_{k=0}^{&#x5C;infty}%20(W)^k"/> denotes the *weighted reachability matrix*, whose <img src="https://latex.codecogs.com/gif.latex?(i,j)^&#x5C;mathrm{th}"/> entry indicates the total influence of node <img src="https://latex.codecogs.com/gif.latex?i"/> on node <img src="https://latex.codecogs.com/gif.latex?j"/> through both direct and indirect connections.[^sum-limits] That is, <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{ij}"/> tells us how much variance at node <img src="https://latex.codecogs.com/gif.latex?j"/> would result from injecting a unit of private variance at node <img src="https://latex.codecogs.com/gif.latex?i"/>. We can equivalently write <img src="https://latex.codecogs.com/gif.latex?&#x5C;Sigma_{ij}%20=%20&#x5C;sum_{k=1}^p%20&#x5C;widetilde{W}_{ik}%20&#x5C;widetilde{W}_{jk}%20s_k"/>.
  
Under passive observation, the squared correlation coefficient can thus be written as
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{aligned}%20%20%20%20r^2(i,j)%20&amp;=%20&#x5C;frac{&#x5C;Sigma_{ij}}{&#x5C;Sigma_{ii}%20&#x5C;Sigma_{jj}}%20&#x5C;&#x5C;%20%20%20%20&amp;=%20&#x5C;frac{&#x5C;left(%20&#x5C;sum_{k=1}^p%20&#x5C;widetilde{W}_{ik}%20&#x5C;widetilde{W}_{jk}%20s_k%20&#x5C;right)^2}{&#x5C;left(&#x5C;sum_{k=1}^p%20&#x5C;widetilde{W}_{ik}^2%20s_k&#x5C;right)&#x5C;left(&#x5C;sum_{k=1}^p%20&#x5C;widetilde{W}_{jk}^2%20s_k&#x5C;right)}.&#x5C;end{aligned}"/></p>  
  
  
==TODO do a quick matlab simulation to check all of this -- some errors may have been introduced when changing notation==
  
This framework also allows us to predict the impact of open- and closed-loop control on the pairwise correlations we expect to observe. To model the application of open-loop control on node <img src="https://latex.codecogs.com/gif.latex?c"/>, we add an arbitrary amount of private variance to <img src="https://latex.codecogs.com/gif.latex?s_c"/>: <img src="https://latex.codecogs.com/gif.latex?s_c%20&#x5C;leftarrow%20s_c%20+%20s_c^{(OL)}"/>. To model the application of closed-loop control on node <img src="https://latex.codecogs.com/gif.latex?c"/>, we first sever inputs to node <img src="https://latex.codecogs.com/gif.latex?c"/> by setting <img src="https://latex.codecogs.com/gif.latex?W_{k,c}%20=%200"/> for <img src="https://latex.codecogs.com/gif.latex?k%20=%201,%20&#x5C;dots%20p"/>, and then set the private variance of node <img src="https://latex.codecogs.com/gif.latex?c"/> by setting <img src="https://latex.codecogs.com/gif.latex?s_c"/> to any arbitrary value. Because <img src="https://latex.codecogs.com/gif.latex?c"/>'s inputs have been severed, this private noise will become exactly node <img src="https://latex.codecogs.com/gif.latex?c"/>'s output variance.
  
!!!! todo [Matt:] add table from `sketches_and_notation/intro-background/causal_vs_expt.md` and modify text above to match
  
[^covariance-derivation]: To see this, denote by <img src="https://latex.codecogs.com/gif.latex?E%20&#x5C;in%20&#x5C;mathbb{R}^{p%20&#x5C;times%20n}"/> the matrix of <img src="https://latex.codecogs.com/gif.latex?n"/> private noise observations for each node. Note that <img src="https://latex.codecogs.com/gif.latex?X%20=%20W^T%20X%20+%20E"/>, so <img src="https://latex.codecogs.com/gif.latex?X%20=%20E(I-W^T)^{-1}"/>. The covariance matrix <img src="https://latex.codecogs.com/gif.latex?&#x5C;Sigma%20=%20&#x5C;mathrm{cov}(X)%20=%20&#x5C;mathbb{E}&#x5C;left[X%20X^T&#x5C;right]"/> can then be written as <img src="https://latex.codecogs.com/gif.latex?&#x5C;Sigma%20=%20&#x5C;mathbb{E}&#x5C;left[%20(I-W^T)^{-1}%20E%20E^T%20(I-W^T)^{-1}%20&#x5C;right]%20=%20(I-W^T)^{-1}%20&#x5C;mathrm{cov}(E)%20(I-W^T)^{-T}%20=%20(I-W^T)^{-1}%20&#x5C;mathrm{diag}(s)%20(I-W^T)^{-T}"/>.
  
[^sum-limits]: We can use <img src="https://latex.codecogs.com/gif.latex?p-1"/> as an upper limit on the sum <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}%20=%20&#x5C;sum_{k=0}^{&#x5C;infty}%20W^k"/> when there are no recurrent connections.
  
  
!!!! todo - Some redundancy with simulation methods; cut and paste anything useful in 4.2 and put into 3.1 / 3.2
  
#  Simulation Methods
  
  
!!!! todo - reorganize / split sections 
  
  
  
  
  
  
@ import "methods0_0_overview.md"
  
  
  
##  Modeling network structure and dynamics
  
!!!! - 70% done
<details><summary>â†ªto do</summary>
  
- [~] read e.g.
- [ ] discuss networks - adj âœ…
- discuss 2 key dimensions of complexity
  - linear-Gaussian v.s. spiking (LIF - Poisson?) ðŸ’«
  - contemporaneous v.s. delayed connections ðŸ’«
- [ ] discuss brian implementation (supplement) ðŸ’«
  
</details>
  
  
We sought to understand both general principles (abstracted across particulars of network implementation) as well as some practical considerations introduced by dealing with spikes and synapses.
  
###  Stochastic network dynamics
  
  
The first approach is accomplished with a network of nodes with Gaussian noise sources, linear interactions, and linear dynamics. The second approach is achieved with a network of nodes consisting of populations of leaky integrate-and-fire (LIF) neurons. These differ from the simpler case in their nonlinear-outputs, arising from inclusion of a spiking threshold. Interactions between neurons happen through spiking synapses, meaning information is passed between neurons sparsely in time[^fr]. 
  
*Neuron dynamics:*
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dV}{dt}%20=%20&#x5C;frac{V_0%20+%20I%20-%20V}{&#x5C;tau_m}%20+%20&#x5C;sigma_m%20&#x5C;sqrt{&#x5C;tau_m}%20&#x5C;xi(t)"/></p>  
  
  
  
[^fr]: However, depending on overall firing rates and population sizes, this sparse spike-based transmission can be coarse-grained to a firing-rate-based model.
  
###  Time-resolvable interactions
  
  
Additionally we study two domains of interactions between populations; contemporaneous and delay-resolvable connections. These domains represent the relative timescales of measurement versus timescale of synaptic delay.
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;text{domain}%20=%20&#x5C;begin{cases}&#x5C;text{contemporaneous},%20&amp;&#x5C;delta_{syn}%20&#x5C;lt%20&#x5C;Delta_{sample}&#x5C;&#x5C;&#x5C;text{delay-resolvable},%20&amp;&#x5C;delta_{syn}%20&#x5C;geq%20&#x5C;Delta_{sample}&#x5C;&#x5C;&#x5C;end{cases}"/></p>  
  
  
>correlation across positive and negative lags between two outputs 
  
In the delay-resolvable domain, directionality of connections may be inferred even under passive observations by looking at temporal precedence - whether the past of one signal is more strongly correlated with future lags of another signal *(i.e. cross-correlation)*. In the contemporaneous domain, network influences act within the time of a single sample[^contemp_sample] so this temporal precedence clue is lost (although directionality can still be inferred in the presence of intervention).
  
The following work is presented with the linear-Gaussian and contemporaneous domains as the default for simplicity and conciseness. 
  
!!!! - talk about the extension to time-resolvable, spiking if it ends up being included
  
[^contemp_sample]: the effective <img src="https://latex.codecogs.com/gif.latex?&#x5C;Delta_{sample}"/> would be broadened in the presence of jitter in connection delay, measurement noise, or temporal smoothing applied post-hoc, leading
  
<details><summary>â†ªconcept figures</summary>
  
![](figures/whiteboard/concept_time_resolved.png )
![](figures/whiteboard/concept_open_loop_contemporaneous.png )
  
</details>
  
###  Code implementation
  
Software for data generation, analysis, and plotting is available at https://github.com/awillats/clinc.
Both linear-Gaussian and spiking networks are simulated with code built from the [Brian2](https://elifesciences.org/articles/47314 ) spiking neural network simulator. This allows for highly modular code with easily interchanged neuron models and standardized output preprocessing and plotting. It was necessary to write an additional custom extension to Brian2 in order to capture delayed linear-Gaussian interactions, available at [brian_delayed_gaussian](https://github.com/awillats/brian_delayed_gaussian ). With this added functionality, it is possible to compare the equivalent network parameters only changing linear-Gaussian versus spiking dynamics and inspect differences solely due to spiking.
  
  
  
!!!! - talk about parameter choices and ranges?
  
*see [_network_parameters_table.md](_network_parameters_table.md ) for list of relevant parameters*
  
  
  
  
  
  
##  Implementing interventions
  
!!!! - 70% done
!!!! - assumed: effect of interventions on theory already address
  
![](figures/core_figure_sketches/figure1_sketch.png )
  
To study the effect of various interventions we simulated inputs to nodes in a network. In the **passive setting**, nodes receive additive drive from *private* Gaussian noise sources common to all neurons within a node, but independent across nodes. The variance of this noise is specified by <img src="https://latex.codecogs.com/gif.latex?&#x5C;sigma_m%20&#x5C;sqrt{&#x5C;tau_m}"/>.[^eq_index]
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dV}{dt}%20=%20&#x5C;frac{V_0%20+%20I%20-%20V}{&#x5C;tau_m}%20+%20&#x5C;sigma_m%20&#x5C;sqrt{&#x5C;tau_m}%20&#x5C;xi(t)"/></p>  
  
  
To emulate **open-loop intervention** we simulated current injection from an external source. This is intended to represent experiments involving stimulation from microelectrodes or optogenetics *(albeit simplifying away any impact of actuator dynamics)*. By default, open-loop intervention is specified as white noise sampled at each timestep from Gaussian distribution with mean and variance <img src="https://latex.codecogs.com/gif.latex?&#x5C;mu_{intv.}"/> and <img src="https://latex.codecogs.com/gif.latex?&#x5C;sigma^2_{intv.}"/>[^res_cont_dyn]
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?I_{open-loop}%20&#x5C;sim%20&#x5C;mathcal{N}(&#x5C;mu_{intv.},&#x5C;,&#x5C;sigma^{2}_{intv.})&#x5C;&#x5C;"/></p>  
  
Ignoring the effect of signal means in the linear-Gaussian setting:
<p align="center"><img src="https://latex.codecogs.com/gif.latex?X_k%20=%20f(&#x5C;sigma^2_m,%20&#x5C;sigma^{2}_{intv.})"/></p>  
  
`per-node indexing needs resolving here also`
  
Ideal **closed-loop control** is able to overwrite the output of a node, setting it precisely to the specified target. 
`making up notation as I go here, needs tightening up:`
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{aligned}T%20&amp;&#x5C;sim%20&#x5C;mathcal{N}(&#x5C;mu_{intv.},&#x5C;,&#x5C;sigma^{2}_{intv.})%20&#x5C;&#x5C;I_{closed-loop}%20&amp;=%20f(X,%20T)%20%20&#x5C;&#x5C;X_k%20|%20CL_{k}%20&amp;&#x5C;approx%20T&#x5C;end{aligned}"/></p>  
  
Note that in this setting, the *output* of a node <img src="https://latex.codecogs.com/gif.latex?X_k"/> under closed-loop control is identical to the target, therefore
<p align="center"><img src="https://latex.codecogs.com/gif.latex?X_k%20|%20CL_{k}%20=%20f(&#x5C;sigma^{2}_{intv.})%20&#x5C;perp%20&#x5C;sigma^2_m"/></p>  
  
In practice, near-ideal control is only possible with very fast measurement and computation relative to the network's intrinsic dynamics, such as in the case of dynamic clamp[^dynamic_clamp]. To demonstrate a broader class of closed-loop interventions (such as those achievable with extracellular recording and stimulation), imperfect "partial" control is simulated by linearly interpolating the output of each node between the target <img src="https://latex.codecogs.com/gif.latex?T"/> and the uncontrolled output based on a control effectiveness parameter <img src="https://latex.codecogs.com/gif.latex?&#x5C;gamma"/>
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?X%20|%20CL_{k,%20&#x5C;gamma}%20=%20&#x5C;gamma%20T%20+%20(1-&#x5C;gamma)%20X"/></p>  
  
  
In the full discrete-time simulation, closed-loop interventions are instead simulated through a proportional-integral-derivative (PID) control policy with control efficacy determined functionally by the strength of controller gains <img src="https://latex.codecogs.com/gif.latex?K%20=%20&#x5C;{k_P,%20k_I,%20k_D&#x5C;}"/> relative to the dynamics of the network.
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?I_{PID}%20=%20&#x5C;text{PID}(X,T|%20K)"/></p>  
  
  
Another interesting intervention to study is **open-loop replay of a closed-loop stimulus**, *that is* taking a particular injected current <img src="https://latex.codecogs.com/gif.latex?I_{CL,&#x5C;,prev}"/> used to drive nodes to a target <img src="https://latex.codecogs.com/gif.latex?T_{prev}"/> and adding it back to the network in a separate trial.
  
Because the instantiation of noise in the network will be different from trial to trial, this "replay" stimulus will no longer adapt sample-by-sample (therefore it should be considered open-loop) and the node's output cannot be expected to match the target precisely, however the statistics of externally applied inputs will be the same. In effect, the comparison between closed-loop and open-loop replay conditions reveals the specific effect of feedback intervention while controlling for any confounds from input statistics.
  
  
[^dynamic_clamp]: NEED dynamic clamp refs - http://www.scholarpedia.org/article/Dynamic_clamp
[^res_cont_dyn]: need to resolve differences in implementation between contemporaneous and voltage simulation cases
[^eq_index]: need to triple check indexing w.r.t. nodes, neurons
  
  
  
  
  
##  Extracting circuit estimates 
  
!!!! - 10% done
  
  
> *refer to methods overview figure*
  
[^inf_techniques]: *inference techniques mentioned in the intro...*
[^corr_prototype]: what does "prototype" mean here? something like MI and corr are equivalent in the linear-Gaussian case, ...
[^corr_hyperparameter]: not sure how important this is. would prefer to set this threshold at some ad-hoc value since we're sweeping other properties. But a more in-depth analysis could look at a receiver-operator curve with respect to this threshold
  
While a broad range of techniques[^inf_techniques] exist for inferring functional relationships from observational data, `(for the majority of this work)` we choose to focus on simple bivariate correlation as a measure of dependence in the linear-Gaussian network. The impact of intervention on this metric is analytically tractable *(see [methods1_predicting_correlation.md](methods1_predicting_correlation.md ))*, and can be thought of as a prototype[^corr_prototype] for more sophisticated measures of dependence such as time-lagged cross-correlations, bivariate and multivariate transfer entropy.
  
  
We implement a naive comparison strategy to estimate the circuit adjacency from emprical correlations; Thresholded empirical correlation matrices are compared to correlation matrices predicted from each circuit in a hypothesis set. Any hypothesized cirucits which are predicted to have a similar correlation structure as is observed (i.e. corr. mats equal after thresholding) are marked as "plausible circuits."[^circuit_search] If only one circuit amongst the hypothesis set is a plausible match, this is considered to be the estimated circuit. The threshold for "binarizing" the empirical correlation matrix is treated as a hyperparameter to be swept at the time of analysis.[^corr_hyperparameter]
  
[^circuit_search]: TODO? formalize notation for this
  
  
  
  
  
  
##  Information-theoretic measures of hypothesis ambiguity
  
!!!! - 10% done
  
*see [_steps_of_inference.md](_steps_of_inference.md ) for entropy writeup*
  
  
#  Results
  
!!!! - overall, 60% done
  
##  Impact of intervention on estimation performance
  
  
  
!!!! todo - comaprison signs in rows of DISAMBIG figure
!!!! todo - merge from "box style" where entrire story is in caption, to having something in body of results text 
!!!! todo - write "explain why CL is better" section, ? exile it to discussion section?
!!!! todo - connect DISAMBIG caption to quantitative variance explanation section
!!!! todo - collapse figvar - do we need to make shared input point here? or is discussion fine?
!!!! todo - dR/dS needs to mention R as r^2 corr
  
  
  
  
  
  
[^node_repr]: nodes in such a graphical model may represent populations of neurons, distinct cell-types, different regions within the brain, or components of a latent variable represented in the brain.
  
  
  
  
###  Intervening provides (categorical) improvements in inference power beyond passive observation
  
!!!! - Application to demo set, entropy over hypotheses - 50% done
  
<details><summary>â†ªnotes, see also </summary>
  
<details><summary>going to assume these have already been discussed</summary>
  
- predicting correlation
- measuring dependence
- markov equivalence
</details>
  
[Methods: Procedure for choosing & applying intervention](_steps_of_inference.md )
  
</details>
  
Next, we apply (steps 1-3 of) this circuit search procedure to a collection of closely related hypotheses for 3 interacting nodes[^node_repr] to illustrate the impact of intervention. ðŸš§ `most of the story in the figure caption for now` ðŸš§
  
<a id="fig-disambig"></a>
![](figures/core_figure_sketches/circuit_entropy_sketch.png )
  
  
> **Figure DISAMBIG: Interventions narrow the set of hypotheses consistent with observed correlations** 
*source: [google drawing](https://docs.google.com/drawings/d/1CBp1MhOW7OGNuBvo7OkIuzqnq8kmN8EEX_AkFuKpVtM/edit )*
>**(A)** Directed adjacency matrices represent the true and hypothesized causal circuit structure
>**(B)** Directed reachability matrices represent the direct *(black)* and indirect *(grey)* influences in a network. Notably, different adjacency matrices can have equivalent reachability matrices making distinguishing between similar causal structures difficult, even with open-loop control.
>**(C)** Correlations between pairs of nodes. Under passive observation, the direction of influence is difficult to ascertain. In densely connected networks, many distinct ground-truth causal structures result in similar "all correlated with all" patterns providing little information about the true structure.
>**(D-F)** The impact of open-loop intervention at each of the nodes in the network is illustrated by modifications to the passive correlation pattern. Thick orange[^edge_color] edges denote correlations which increase above their baseline value with high variance open-loop input. Thin blue[^edge_color] edges denote correlations which decrease, often as a result of increased connection-independent "noise" variance in one of the participating nodes. Grey edges are unaffected by intervention at that location.
> A given hypotheses set (A) will result in an "intervention-specific fingerprint", that is a distribution of frequencies for observing patterns of modified correlations *(across a single row within D-F)*. If this fingerprint contains many examples of the same pattern of correlation (such as **B**), many hypotheses correspond to the same observation, and that experiment contributes low information to distinguish between structures. A maximally informative intervention would produce a unique pattern of correlation for each member of the hypothesis set.
:construction:`caption too long`
  
  
  
  
[^edge_color]: will change the color scheme for final figure. Likely using orange and blue to denote closed and open-loop interventions. Will also add in indication of severed edges
  
!!!! - Explain why closed-loop helps - link severing - 5% done
  
**Why does closed-loop control provide a categorical advantage?** Because it severs indirect links
`is this redundant with intro?`
`needs to be backed here up by aggregate results?`
- this is especially relevant in recurrently connected networks where the reachability matrix becomes more dense. 
- more stuff is connected to other stuff, so there are more indirect connections, and the resulting correlations look more similar (more circuits in the equivalence class)
- patterns of correlation become more specific with increasing intervention strength 
  - more severed links â†’ more unique adjacency-specific patterns of correlation  
  
> **Where you intervene**[^where_place] strongly determines the inference power of your experiment.
> **secondary point:** having (binary) prediction helps capture this relationship
  
[^where_place]: Figure VAR shows this pretty well, perhaps sink this section until after discussing categorical and quantitative?
---
  
!!!! - Quantitative impact of closed-loop - 70% done
###  Stronger intervention shapes correlation, resulting in more data-efficient inference with less bias
  
  
!!!! - Explain why closed-loop helps - bidirectional variance control - 60% done
[^dof]: need a more specific way of stating this. I mean degrees of freedom in the sense that mean and variance can be controlled independent of each other. And also, that the range of achievable correlation coefficients is wider for closed-loop than open-loop (where instrinsic variability constrains the minimum output variance)
  
[^intrinsic_var]: below the level set by added, independent/"private" sources
  
While a primary advantage of closed-loop interventions for circuit inference is its ability to functionally lesion indirect connections, another, more nuanced `(quantitative)` advantage of closed-loop control lies in its capacity to bidirectionally control output variance. While the variance of an open-loop stimulus can be titrated to adjust the output variance at a node, in general, an open-loop stimulus cannot reduce this variance below its instrinsic[^intrinsic_var] variability. That is, if the system is linear with Gaussian noise,
  
!!!! todo - this is very closely related to 4.2 implementing interventions, description of impact of intervention on variance should perhaps be moved there... or the supplement?
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{open},&#x5C;sigma^2_S)%20&#x5C;geq%20&#x5C;mathbb{V}_{i}(C)"/></p>  
  
More specifically, if the open-loop stimulus is statistically independent from the intrinsic variability[^open_loop_independent]
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{open},&#x5C;sigma^2_S)%20=%20&#x5C;mathbb{V}_{i}(C)%20+%20&#x5C;sigma^2_S"/></p>  
  
Applying closed-loop to a linear Gaussian circuit:
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{align}&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{closed},&#x5C;sigma^2_S)%20&amp;=%20&#x5C;sigma^2_S%20&#x5C;&#x5C;&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{closed},&#x5C;sigma^2_S)%20&amp;&#x5C;perp%20&#x5C;mathbb{V}_{i}(C)&#x5C;end{align}"/></p>  
  
  
<details><summary> â†ª Firing rates couple mean and variance </summary> 
  
In neural circuits, we're often interested in firing rates, which are non-negative. This particular output nonlinearity means that the linear Gaussian assumptions do not hold, especially in the presence of strong inhibitory inputs. In this setting, firing rate variability is coupled to its mean rate; Under a homoeneous-rate Poisson assumption, mean firing rate and firing rate variability would be proportional. With inhibitory inputs, open-loop stimulus can drive firing rates low enough to reduce their variability. Here, feedback control still provides an advantage in being able to control the mean and variance of firing rates independently[^cl_indp_practical]
  
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;begin{align}&#x5C;mu^{out}_i%20&amp;=%20f(&#x5C;mu^{in}_i,%20&#x5C;mathbb{V}^{in}_i)&#x5C;&#x5C;&#x5C;mathbb{V}^{out}_{i}(C)%20&amp;=%20f(&#x5C;mu^{out}_i,%20&#x5C;mathbb{V}^{in}_i)&#x5C;end{align}"/></p>  
  
</details>
  
<details><summary> â†ª Notes on imperfect control </summary> 
  
`Ideal control`
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{closed},&#x5C;sigma^2_S)%20=%20&#x5C;sigma^2_S"/></p>  
  
`Imperfect control` - intuitively feedback control is counteracting / subtracting disturbance due to unobserved sources, including intrinsic variability. We could summarize the effectiveness of closed-loop disturbance rejection with a scalar <img src="https://latex.codecogs.com/gif.latex?0&#x5C;leq&#x5C;gamma&#x5C;leq1"/>
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{closed},&#x5C;sigma^2_S)%20=%20&#x5C;mathbb{V}_{i}(C)%20-%20&#x5C;gamma&#x5C;mathbb{V}_{i}(C)%20+%20&#x5C;sigma^2_S%20&#x5C;&#x5C;&#x5C;mathbb{V}_{i}(C|S=&#x5C;text{closed},&#x5C;sigma^2_S)%20=%20(1-&#x5C;gamma)%20&#x5C;mathbb{V}_{i}(C)%20+%20&#x5C;sigma^2_S"/></p>  
  
</details>
  
[^open_loop_independent]: notably, this is part of the definition of open-loop intervention
[^cl_indp_practical]: practically, this requires very fast feedback to achieve fully independent control over mean and variance. In the case of firing rates, I suspect <img src="https://latex.codecogs.com/gif.latex?&#x5C;mu%20&#x5C;leq%20&#x5C;alpha&#x5C;mathbb{V}"/>, so variances can be reduced, but for very low firing rates, there's still an upper limit on what the variance can be.
  
  
!!!! - reference [figvar](#fig-var ) to empricially show this bidirectional control of output variance?
  
  
####  Impact of intervention location and variance on pariwise correlations
  
  
  
  
[related methods](methods1_predicting_correlation.md )
  
!!!! TODO - again, feels very backgroundy / discussiony ... where to put this?
  
We have shown that closed-loop interventions provide more flexible control over output variance of nodes in a network, and that shared and independent sources of variance determine pairwise correlations between node outputs. Together, this suggests closed-loop interventions may allow us to shape the pattern of correlations with more degrees of freedom[^dof] `[why do we want to?...]`
  
One application of this increased flexibility is to increase correlations associated with pairs of directly correlated nodes, while decreasing spurious correlations associated with pairs of nodes without a direct connection (but perhaps are influenced by a common input, or are connected only indirectly). While "correlation does not imply causation," intervention may decrease the gap between the two. 
  
Our hypothesis is that this shaping of pairwise correlations will result in reduced false positive edges in inferred circuits, "unblurring" the indirect associations that would otherwise confound circuit inference. However care must be taken, as this strategy relies on a hypothesis for the ground truth adjacency and may also result in a "confirmation bias" as new spurious correlations can be introduced through closed-loop intervention.
  
The impact of intervention on correlations can be summarized through the co-reachability <img src="https://latex.codecogs.com/gif.latex?&#x5C;text{CoReach}(i,j|S_k)"/>. A useful distillation of this mapping is to understand the sign of <img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dR_{ij}}{dS_k}"/>, that is whether increasing the variance of an intervention at node <img src="https://latex.codecogs.com/gif.latex?k"/> increases or decreases the correlation between nodes <img src="https://latex.codecogs.com/gif.latex?i"/> and <img src="https://latex.codecogs.com/gif.latex?j"/>
  
In a simulated network Aâ†’B [(fig. variance)](#fig-var ) we demonstrate predicted and emprirical correlations between a pair of nodes as a function of intervention type, location, and variance. A few features are present which provide a general intuition for the impact of intervention location in larger circuits: First, interventions "upstream" of a true connection [(lower left, fig. variance)](#fig-var ) tend to increase the connection-related variance, and therefore strengthen the observed correlations.
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;text{Reach}(S_kâ†’i)%20&#x5C;neq%200%20&#x5C;&#x5C;%20&#x5C;text{Reach}(iâ†’j)%20&#x5C;neq%200%20&#x5C;&#x5C;%20&#x5C;frac{dR}{dS_k}%20&gt;%200"/></p>  
  
  
Second, interventions affecting only the downstream node [(lower right, fig. variance)](#fig-var ) of a true connection introduce variance which is independent of the connection Aâ†’B, decreasing the observed correlation.
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;text{Reach}(S_k%20â†’%20j)%20=%200%20&#x5C;&#x5C;%20&#x5C;text{Reach}(S_k%20â†’%20j)%20&#x5C;neq%200%20&#x5C;&#x5C;%20&#x5C;frac{dR}{dS_k}%20&lt;%200"/></p>  
  
  
Third, interventions which reach both nodes will tend to increase the observed correlations [(upper left, fig. variance)](#fig-var ), moreover this can be achieved even if no direct connection <img src="https://latex.codecogs.com/gif.latex?iâ†’j"/> exists.
<p align="center"><img src="https://latex.codecogs.com/gif.latex?&#x5C;text{Reach}(S_k%20â†’%20i)%20&#x5C;neq%200%20&#x5C;&#x5C;%20&#x5C;text{Reach}(S_k%20â†’%20j)%20&#x5C;neq%200%20&#x5C;&#x5C;%20&#x5C;text{Reach}(i%20â†’%20j)%20=%200%20&#x5C;&#x5C;%20&#x5C;frac{dR}{dS_k}%20&gt;%200"/></p>  
  
  
Notably, the impact of an intervention which is a "common cause" for both nodes depends on the relative weighted reachability between the source and each of the nodes. Correlations induced by a common cause are maximized when the input to each node is equal, that is <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{S_kâ†’i}%20&#x5C;approx%20&#x5C;widetilde{W}_{S_kâ†’j}"/> (upper right * in [fig. variance](#fig-var )). If iâ†’j are connected <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{S_kâ†’i}%20&#x5C;gg%20&#x5C;widetilde{W}_{S_kâ†’j}"/> results in an variance-correlation relationship similar to the "upstream source" case (increasing source variance increases correlation <img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dR}{dS_k}%20&gt;%200"/>),
 while <img src="https://latex.codecogs.com/gif.latex?&#x5C;widetilde{W}_{S_kâ†’i}%20&#x5C;ll%20&#x5C;widetilde{W}_{S_kâ†’j}"/> results in a relationship similar to the "downstream source" case (<img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dR}{dS_k}%20&lt;%200"/>)[^verify_drds]
  
[^verify_drds]: not 100% sure this is true, the empirical results are really pointing to dR/dW<0 rather than dR/dS<0. Also this should really be something like <img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{d|R|}{dS}"/> or <img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dr^2}{dS}"/> since these effects decrease the *magnitude* of correlations. I.e. if <img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{d|R|}{dS}%20&lt;%200"/> increasing <img src="https://latex.codecogs.com/gif.latex?S"/> might move <img src="https://latex.codecogs.com/gif.latex?r"/> from <img src="https://latex.codecogs.com/gif.latex?-0.8"/> to <img src="https://latex.codecogs.com/gif.latex?-0.2"/>, i.e. decrease its magnitude not its value.
  
<a id="fig-predict"></a>
  
  
  
  
![](figures/misc_figure_sketches/quant_r2_prediction_common.png )
![](figures/from_code/bidirectional_correlation.png "generated by sweep_gaussian_SNR.py")
  
> ðŸš§(Final figure will be a mix of these two panels, caption will need updating) **Figure VAR: Location, variance, and type of intervention shape pairwise correlations**
> **(CENTER)** A two-node linear Gaussian network is simulated with a connection from Aâ†’B. Open-loop interventions *(blue)* consist of independent Gaussian inputs with a range of variances <img src="https://latex.codecogs.com/gif.latex?&#x5C;sigma^2_S"/>. Closed-loop interventions *(orange)* consist of feedback control with an independent Gaussian target with a range of variances. *Incomplete closed-loop interventions result in node outputs which are a mix of the control target and network-driven activity*. Connections from sources to nodes are colored by their impact on correlations between A and B; green denotes <img src="https://latex.codecogs.com/gif.latex?dR&#x2F;dS%20&gt;%200"/>, red denotes <img src="https://latex.codecogs.com/gif.latex?dR&#x2F;dS&lt;0"/>.
> **(lower left)** Intervention "upstream" of the connection Aâ†’B increases the correlation <img src="https://latex.codecogs.com/gif.latex?r^2(A,B)"/>.
> **(lower right)** Intervention at the terminal of the connection Aâ†’B decreases the correlation <img src="https://latex.codecogs.com/gif.latex?r^2(A,B)"/> by adding connection-independent noise.
> **(upper left)** Intervention with shared inputs to both nodes generally increases <img src="https://latex.codecogs.com/gif.latex?r^2(A,B)"/>, *(even without Aâ†’B, see supplement)*.
> **(upper right)** The impact of shared interventions depends on relative weighted reachability <img src="https://latex.codecogs.com/gif.latex?&#x5C;text{Reach}(S_kâ†’A)%20&#x2F;%20&#x5C;text{Reach}(S_kâ†’B)"/>, with highest correlations when these terms are matched (see *)
> Closed-loop interventions *(orange)* generally result in larger changes in correlation across <img src="https://latex.codecogs.com/gif.latex?&#x5C;sigma^2_S"/> than the equivalent open-loop intervention. Closed-loop control at B effectively lesions the connection Aâ†’B, resulting in near-zero correlation.
> [^var_compare]
  
  
[^var_compare]: compare especially to ["Transfer Entropy as a Measure of Brain Connectivity"](https://www.frontiersin.org/articles/10.3389/fncom.2020.00045/full ), ["How Connectivity, Background Activity, and Synaptic Properties Shape the Cross-Correlation between Spike Trains"](https://www.jneurosci.org/content/29/33/10234 ) Figure 3.
  
  
  
<details><summary>â†ª additional notes:</summary>
  
- contextualize increasing correlation is sometimes good, sometimes bad!
- having (quantitative) prediction helps capture this relationship
- **(incidental) subfigure PREDICT: Comparing predicted and empirical correlation, identification performance**
</details>
  
ðŸš§
The change in correlation as a function of changing intervention variance (<img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{dr^2_{ij}}{dS}"/>) can therefore be used as an additional indicator of presence/absence and directionality of the connection between A,B *(see [fig. disambig. D.)](fig-disambig ))*
ðŸš§
  
  
[Fig. variance](#fig-var ) also demonstrates the relative dynamic range of correlations achievable under passive, open- and closed-loop intervention. In the passive case, correlations are determined by instrinsic properties of the network <img src="https://latex.codecogs.com/gif.latex?&#x5C;sigma^2_{base}"/>. These properties have influence over the observed correlations in a way that can be difficult to separate from differences due to the ground-truth circuit. With open-loop intervention we can observe the impact of increasing variance at a particular node, but the dynamic range of achievable correlations is bounded by not being able to reduce variance below its baseline level. With closed-loop control, the bidirectional control of the output variance for a node means a much wider range of correlations can be achieved [(blue v.s. orange in fig. variance)](#fig-var ), resulting in a more sensitive signal reflecting the ground-truth connectivity.
  
  
  
  
  
*see also [results1B_data_efficiency_and_bias.md](results1B_data_efficiency_and_bias.md )*
  
  
<details><summary>â†ªNotes from matt</summary>
  
- [super minor] First part of fig DISAMBIG: subsections (A) through (C) work really well
- [super minor] in caption for (D-F): "modifications to the passive correlation pattern" is a bit confusing in the context of open-loop intervention
- [super minor] also in caption for (D-F): really like "intervention-specific fingerprint" terminology. The last sentence of the (D-F) caption really hits the message home, possible to emphasize that this is the take-home message earlier?
- [narrative/organization] fig DISAMBIG feels really example-y, more like a proof of concept than 'results.' The writing in Sec 5.1.1 also has this flavor, like it could be in a methods section. (The plot in the top right feels much more results-ey.) Not necessarily a bad thing, maybe just a consideration for thinking about article vs perspective flavor.
- [missing] Section 5.1.2.1: what are the definitions of S_k, CoReach(i,j|S_k), and R_{ij}?
- [narrative] Section 5.1.2.1: the narrative here really works for me, but it's a little unclear whether this is more of a 'result' or a 'recipe' -- the figures here also feel more example/proof-of-concept-ey, and the math here helps ground things in
- [missing] discussion of partial closed-loop control?
</details>
  
  
  
  
  
#  Discussion
  
  
*see [limitations_future_work.md](sketches_and_notation/discussion/limitations_future_work.md )*
  
  
#  References
  
*see [pandoc pandoc-citations](https://github.com/shd101wyy/markdown-preview-enhanced/blob/master/docs/pandoc-bibliographies-and-citations.md )*
  
#  Supplement
  
  
  
  