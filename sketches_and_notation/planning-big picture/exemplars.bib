
@book{fakhar_causal_2020,
	title = {Causal {Brain} {Mapping} of {Artificial} {Neural} {Networks} by {Game} {Theory}: {A} {Case} for in-silico {Multi}-{Perturbation} {Experiments}},
	shorttitle = {Causal {Brain} {Mapping} of {Artificial} {Neural} {Networks} by {Game} {Theory}},
	abstract = {Elucidating causal relations between the brain and its produced behaviour is a fundamental neuroscientific goal. Traditional approaches for revealing such relations have relied on univariate single-site lesion experiments in which an individual brain region is perturbed and consequent behavioural effects are quantified. More recent studies, however, have pointed towards the inefficiency of single-site perturbations to reveal reliable neural contributions, arguing for more extensive perturbational regimes and analyses, e.g., multi-site perturbation approaches. This study aims to compare uni- and multi-site perturbation approaches using an Artificial Neural Network model to elucidate their inferential capabilities.},
	author = {Fakhar, Kayson and Hilgetag, Claus},
	month = sep,
	year = {2020},
	doi = {10.13140/RG.2.2.29018.77769},
	file = {Full Text PDF:/Users/adam/Zotero/storage/IZSGLMXM/Fakhar and Hilgetag - 2020 - Causal Brain Mapping of Artificial Neural Networks.pdf:application/pdf},
}

@techreport{fakhar_systematic_2021,
	type = {preprint},
	title = {Systematic {Perturbation} of an {Artificial} {Neural} {Network}: {A} {Step} {Towards} {Quantifying} {Causal} {Contributions} in {The} {Brain}},
	shorttitle = {Systematic {Perturbation} of an {Artificial} {Neural} {Network}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.11.04.467251},
	abstract = {Lesion inference analysis is a fundamental approach for characterizing the causal contributions of neural elements to brain function. Historically, it has helped to localize specialized functions in the brain after brain damage, and it has gained new prominence through the arrival of modern optogenetic perturbation techniques that allow probing the functional contributions of neural circuit elements at unprecedented levels of detail.},
	language = {en},
	urldate = {2021-11-05},
	institution = {Neuroscience},
	author = {Fakhar, Kayson and Hilgetag, Claus Christian},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.04.467251},
	file = {Fakhar and Hilgetag - 2021 - Systematic Perturbation of an Artificial Neural Ne.pdf:/Users/adam/Zotero/storage/6CIRERWS/Fakhar and Hilgetag - 2021 - Systematic Perturbation of an Artificial Neural Ne.pdf:application/pdf},
}

@techreport{lepperod_inferring_2018,
	title = {Inferring causal connectivity from pairwise recordings and optogenetics},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/463760v2},
	abstract = {To study how the brain works, it is crucial to identify causal interactions between neurons, which is thought to require perturbations. However, when using optogenetics we typically perturb multiple neurons, producing a confound - any of the stimulated neurons can have affected the postsynaptic neuron. Here we show how this produces large biases, and how they can be reduced using the instrumental variable (IV) technique from econometrics. The interaction between stimulation and the absolute refractory period produces a weak, approximately random signal which can be exploited to estimate causal connectivity. When simulating integrate-and-fire neurons, we find that estimates from IV are better than naïve techniques (R2 = 0.77 vs R2 = 0.01). The difference is important as the estimates disagree when applied to experimental data from stimulated neurons with recorded spiking activity. Presented is a robust analysis framework for mapping out network connectivity based on causal neuron interactions.},
	language = {en},
	urldate = {2022-01-27},
	institution = {bioRxiv},
	author = {Lepperød, Mikkel Elle and Stöber, Tristan and Hafting, Torkel and Fyhn, Marianne and Kording, Konrad Paul},
	month = nov,
	year = {2018},
	doi = {10.1101/463760},
	note = {Section: New Results
Type: article},
	pages = {463760},
	file = {Full Text PDF:/Users/adam/Zotero/storage/F5LC44EM/Lepperød et al. - 2018 - Inferring causal connectivity from pairwise record.pdf:application/pdf;Snapshot:/Users/adam/Zotero/storage/Z3T467H7/463760v2.html:text/html},
}

@article{reid_advancing_2019,
	title = {Advancing functional connectivity research from association to causation},
	volume = {22},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0510-4},
	doi = {10.1038/s41593-019-0510-4},
	abstract = {Cognition and behavior emerge from brain network interactions, such that investigating causal interactions should be central to the study of brain function. Approaches that characterize statistical associations among neural time series—functional connectivity (FC) methods—are likely a good starting point for estimating brain network interactions. Yet only a subset of FC methods (‘effective connectivity’) is explicitly designed to infer causal interactions from statistical associations. Here we incorporate best practices from diverse areas of FC research to illustrate how FC methods can be refined to improve inferences about neural mechanisms, with properties of causal neural interactions as a common ontology to facilitate cumulative progress across FC approaches. We further demonstrate how the most common FC measures (correlation and coherence) reduce the set of likely causal models, facilitating causal inferences despite major limitations. Alternative FC measures are suggested to immediately start improving causal inferences beyond these common FC measures.},
	language = {en},
	number = {11},
	urldate = {2022-02-09},
	journal = {Nature Neuroscience},
	author = {Reid, Andrew T. and Headley, Drew B. and Mill, Ravi D. and Sanchez-Romero, Ruben and Uddin, Lucina Q. and Marinazzo, Daniele and Lurie, Daniel J. and Valdés-Sosa, Pedro A. and Hanson, Stephen José and Biswal, Bharat B. and Calhoun, Vince and Poldrack, Russell A. and Cole, Michael W.},
	month = nov,
	year = {2019},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Cognitive neuroscience, Network models, Neural circuits},
	pages = {1751--1760},
	file = {Full Text PDF:/Users/adam/Zotero/storage/ER87K3ZP/Reid et al. - 2019 - Advancing functional connectivity research from as.pdf:application/pdf;Snapshot:/Users/adam/Zotero/storage/EBLW72RJ/s41593-019-0510-4.html:text/html},
}

@article{das_systematic_2020,
	title = {Systematic errors in connectivity inferred from activity in strongly recurrent networks},
	volume = {23},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-0699-2},
	doi = {10.1038/s41593-020-0699-2},
	abstract = {Understanding the mechanisms of neural computation and learning will require knowledge of the underlying circuitry. Because it is difficult to directly measure the wiring diagrams of neural circuits, there has long been an interest in estimating them algorithmically from multicell activity recordings. We show that even sophisticated methods, applied to unlimited data from every cell in the circuit, are biased toward inferring connections between unconnected but highly correlated neurons. This failure to ‘explain away’ connections occurs when there is a mismatch between the true network dynamics and the model used for inference, which is inevitable when modeling the real world. Thus, causal inference suffers when variables are highly correlated, and activity-based estimates of connectivity should be treated with special caution in strongly connected networks. Finally, performing inference on the activity of circuits pushed far out of equilibrium by a simple low-dimensional suppressive drive might ameliorate inference bias.},
	language = {en},
	number = {10},
	urldate = {2022-02-09},
	journal = {Nature Neuroscience},
	author = {Das, Abhranil and Fiete, Ila R.},
	month = oct,
	year = {2020},
	note = {Number: 10
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Network models, Neural circuits},
	pages = {1286--1296},
	file = {Full Text PDF:/Users/adam/Zotero/storage/WWQCFDIH/Das and Fiete - 2020 - Systematic errors in connectivity inferred from ac.pdf:application/pdf;Snapshot:/Users/adam/Zotero/storage/MNAPVTJX/s41593-020-0699-2.html:text/html},
}

@article{marinescu_quasi-experimental_2018,
	title = {Quasi-experimental causality in neuroscience and behavioural research {\textbar} {Nature} {Human} {Behaviour}},
	volume = {2},
	url = {https://www.nature.com/articles/s41562-018-0466-5},
	abstract = {In many scientific domains, causality is the key question. For example, in neuroscience, we might ask whether a medication affects perception, cognition or action. Randomized controlled trials are the gold standard to establish causality, but they are not always practical. The field of empirical economics has developed rigorous methods to establish causality even when randomized controlled trials are not available. Here we review these quasi-experimental methods and highlight how neuroscience and behavioural researchers can use them to do research that can credibly demonstrate causal effects.},
	urldate = {2022-02-09},
	journal = {Nature Human Behavior},
	author = {{Ioana E. Marinescu} and {Patrick N. Lawlor} and {Konrad P. Kording}},
	year = {2018},
	pages = {891--898},
	file = {Marinescu et al. - Quasi-experimental causality in neuroscience and b.pdf:/Users/adam/Zotero/storage/54SKZC7X/Marinescu et al. - Quasi-experimental causality in neuroscience and b.pdf:application/pdf;Quasi-experimental causality in neuroscience and behavioural research | Nature Human Behaviour:/Users/adam/Zotero/storage/Z3NQHT47/s41562-018-0466-5.html:text/html},
}

@article{jonas_could_2017,
	title = {Could a {Neuroscientist} {Understand} a {Microprocessor}?},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268},
	doi = {10.1371/journal.pcbi.1005268},
	abstract = {There is a popular belief in neuroscience that we are primarily data limited, and that producing large, multimodal, and complex datasets will, with the help of advanced data analysis algorithms, lead to fundamental insights into the way the brain processes information. These datasets do not yet exist, and if they did we would have no way of evaluating whether or not the algorithmically-generated insights were sufficient or even correct. To address this, here we take a classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the microprocessor. This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data. Additionally, we argue for scientists using complex non-linear dynamical systems with known ground truth, such as the microprocessor as a validation platform for time-series and structure discovery methods.},
	language = {en},
	number = {1},
	urldate = {2022-02-09},
	journal = {PLOS Computational Biology},
	author = {Jonas, Eric and Kording, Konrad Paul},
	month = jan,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Behavior, Behavioral neuroscience, Computational neuroscience, Connectomics, Microprocessors, Neuronal tuning, Neurons, Neuroscience},
	pages = {e1005268},
	file = {Full Text PDF:/Users/adam/Zotero/storage/RFKVFTB7/Jonas and Kording - 2017 - Could a Neuroscientist Understand a Microprocessor.pdf:application/pdf;Snapshot:/Users/adam/Zotero/storage/KXADS2C7/article.html:text/html},
}
