<!DOCTYPE html><html><head>
      <title>Closed-Loop Identifiability in Neural Circuits</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"],"imageFont":null},"root":"file:///Users/adam/.dotfiles/atom/packages/markdown-preview-enhanced/node_modules/@shd101wyy/mume/dependencies/mathjax"});
        </script>
        <script type="text/javascript" async src="file:////Users/adam/.dotfiles/atom/packages/markdown-preview-enhanced/node_modules/@shd101wyy/mume/dependencies/mathjax/MathJax.js" charset="UTF-8"></script>
        
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  /* Heading numbering, inspired by Typora 
     https://support.typora.io/Auto-Numbering/
    */
  font-size: 11pt;
  line-height: 2;
  text-align: justify;
  text-justify: distribute;
  font-family: Times;
  counter-reset: h1;
}
.markdown-preview.markdown-preview h1,
.markdown-preview.markdown-preview h2 {
  text-align: center;
}
.markdown-preview.markdown-preview h1,
.markdown-preview.markdown-preview h2,
.markdown-preview.markdown-preview h3,
.markdown-preview.markdown-preview h4,
.markdown-preview.markdown-preview h5 {
  font-size: 12pt;
}
.markdown-preview.markdown-preview h1 {
  font-size: 14pt;
}
.markdown-preview.markdown-preview h3 {
  text-decoration: underline;
  font-weight: normal;
}
.markdown-preview.markdown-preview h4 {
  font-style: italic;
  font-weight: normal;
}
.markdown-preview.markdown-preview h1 {
  counter-reset: h2;
}
.markdown-preview.markdown-preview h2 {
  counter-reset: h3;
}
.markdown-preview.markdown-preview h3 {
  counter-reset: h4;
}
.markdown-preview.markdown-preview h4 {
  counter-reset: h5;
}
.markdown-preview.markdown-preview h5 {
  counter-reset: h6;
}
.markdown-preview.markdown-preview h1:before {
  counter-increment: h1;
  content: counter(h1) ". ";
}
.markdown-preview.markdown-preview h2:before {
  counter-increment: h2;
  content: counter(h1) "." counter(h2) ". ";
}
.markdown-preview.markdown-preview h3:before {
  counter-increment: h3;
  content: counter(h1) "." counter(h2) "." counter(h3) ". ";
}
.markdown-preview.markdown-preview h4:before {
  counter-increment: h4;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) ". ";
}
.markdown-preview.markdown-preview h5:before {
  counter-increment: h5;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) "." counter(h5) ". ";
}
.markdown-preview.markdown-preview h6:before {
  counter-increment: h6;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) "." counter(h5) "." counter(h6) ". ";
}
@page {
  size: A4 portrait;
  margin-left: 1.5in;
  margin-right: 1in;
  margin-bottom: 1.5in;
}
.do-number-sections {
  counter-reset: h1;
}
.do-number-sections h1 {
  counter-reset: h2;
}
.do-number-sections h2 {
  counter-reset: h3;
}
.do-number-sections h3 {
  counter-reset: h4;
}
.do-number-sections h4 {
  counter-reset: h5;
}
.do-number-sections h5 {
  counter-reset: h6;
}
.do-number-sections h1:before {
  counter-increment: h1;
  content: counter(h1) ". ";
}
.do-number-sections h2:before {
  counter-increment: h2;
  content: counter(h1) "." counter(h2) ". ";
}
.do-number-sections h3:before {
  counter-increment: h3;
  content: counter(h1) "." counter(h2) "." counter(h3) ". ";
}
.do-number-sections h4:before {
  counter-increment: h4;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) ". ";
}
.do-number-sections h5:before {
  counter-increment: h5;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) "." counter(h5) ". ";
}
.do-number-sections h6:before {
  counter-increment: h6;
  content: counter(h1) "." counter(h2) "." counter(h3) "." counter(h4) "." counter(h5) "." counter(h6) ". ";
}

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 id="abstract">Abstract</h1>
<p>The necessity of intervention in inferring cause has long been
understood in neuroscience. Recent work has highlighted the limitations
of passive observation and single-site lesion studies in accurately
recovering causal circuit structure. The advent of optogenetics has
facilitated increasingly precise forms of intervention including
closed-loop control which may help eliminate confounding influences.
However, it is not yet clear how best to apply closed-loop control to
leverage this increased inferential power. In this paper, we use tools
from causal inference, control theory, and neuroscience to show when and
how closed-loop interventions can more effectively reveal causal
relationships.
<code>We also examine the performance of standard network inference procedures in simulated spiking networks under passive, open-loop and closed-loop conditions.</code>
We demonstrate a unique capacity of feedback control to distinguish
competing circuit hypotheses by disrupting connections which would
otherwise result in equivalent patterns of correlation<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.
Our results build toward a practical framework to improve design of
neuroscience experiments to answer causal questions about neural
circuits.</p>
<h1 id="introduction">Introduction</h1>
<h2 id="estimating-causal-interactions-in-the-brain">Estimating causal
interactions in the brain</h2>
<p>Many hypotheses about neural circuits are phrased in terms of causal
relationships: &#x201C;will changes in activity to this region of the brain
produce corresponding changes in another region?&#x201D; Understanding these
causal relationships is critical to both scientific understanding and to
developing effective therapeutic interventions, which require knowledge
of how potential therapies will impact brain activity and patient
outcomes.</p>
<p>A range of mathematical and practical challenges make it difficult to
determine these causal relationships. In studies that rely only
observational data, it is often impossible to determine whether observed
patterns of activity are caused by known and controlled inputs, or
whether they are instead spurious connections generated by recurrent
activity, indirect relationships, or unobserved &#x201C;confounders.&#x201D; It is
generally understood that moving from experiments involving passive
observation to more complex levels of intervention allows experimenters
to better tackle challenges to circuit identification. However, while
chemical and surgical lesion experiments have historically been employed
to remove the influence of possible confounds, they are likely to
dramatically disrupt circuits from their typical functions, making
conclusions about underlying causal structure drawn from these
experiments unlikely to hold in naturalistic settings <span class="citation" data-cites="chicharro2012when">(Chicharro and Ledberg
2012)</span>. <em>Closed-loop</em> interventions [&#x2026;]</p>
<p>Despite the promise of these closed-loop strategies for identifying
causal relations in neural circuits, however, it is not yet fully
understood <em>when</em> more complex intervention strategies can
provide additional inferential power, or <em>how</em> these experiments
should be optimally designed. In this paper we demonstrate when and how
closed-loop interventions can reveal the causal structure governing
neural circuits. Drawing from ideas in causal inference <span class="citation" data-cites="pearl2009causality maathuis2016review chis2011structural">(Pearl
2009; Maathuis and Nandy 2016; Chis, Banga, and Balsa-Canto
2011)</span>, we describe the classes of models that can be
distinguished by a given set of input-output experiments, and what
experiments are necessary to uniquely determine specific causal
relationships.</p>
<p>We first propose a mathematical framework that describes how open-
and closed-loop interventions impact observable qualities of neural
circuits. Using this framework, experimentalists propose a set of
candidate hypotheses describing the potential causal structure of the
circuit under study, and then select a series of interventions that best
allows them to distinguish between these hypotheses. Using both simple
<code>controlled models and in silico models</code><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> of
spiking networks, we explore factors that govern the efficacy of these
types of interventions. Guided by the results of this exploration, we
present a set of recommendations that can guide the design of open- and
closed-loop experiments to better uncover the causal structure
underlying neural circuits.</p>
<p><strong>Inferring causal interactions from time series.</strong> A
number of strategies have been proposed to detect causal relationships
between observed variables. Wiener-Granger (or predictive) causality
states that a variable <span class="math inline">\(X\)</span>
&#x201C;Granger-causes&#x201D; <span class="math inline">\(Y\)</span> if <span class="math inline">\(X\)</span> contains information relevant to <span class="math inline">\(Y\)</span> that is not contained in <span class="math inline">\(Y\)</span> itself or any other variable <span class="citation" data-cites="wiener1956theory">(Wiener 1956)</span>.
This concept has traditionally been operationalized with vector
autoregressive models <span class="citation" data-cites="granger1969investigating">(Granger 1969)</span>; the
requirement that <em>all</em> potentially causative variables be
considered makes these notions of dependence susceptible to unobserved
confounders <span class="citation" data-cites="runge2018causal">(Runge
2018)</span>.</p>
<p>Our work initially focuses on measures of directional interaction
that are based on lagged correlations<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span class="citation" data-cites="melssen1987detection">(Melssen and Epping 1987)</span>.
These metrics look at the correlation of time series collected from
pairs of nodes at various lags and detect peaks at negative time lags.
Such peaks could indicate the presence of a direct causal relationship &#x2013;
but they could also stem from indirect causal links or hidden
confounders <span class="citation" data-cites="dean2016dangers">(Dean
and Dunsmuir 2016)</span>. In these bivariate correlation methods, it is
thus necessary to consider patterns of correlation between many pairs of
nodes in order to differentiate between direct, indirect, and
confounding relationships <span class="citation" data-cites="dean2016dangers">(Dean and Dunsmuir 2016)</span>. This
distinguishes these strategies from some multivariate methods that
&#x201C;control&#x201D; for the effects of potential confounders. While
cross-correlation-based measures are generally limited to detecting
linear functional relationships between nodes, their computational
feasibility makes them a frequent metric of choice in experimental
neuroscience work <span class="citation" data-cites="knox1981detection salinas2001correlated garofalo2009evaluation">(Knox
1981; Salinas and Sejnowski 2001; Garofalo et al. 2009)</span>.</p>
<p>Other techniques detect directional interaction stemming from more
general or complex relationships. Information-theoretic methods, which
use information-based measures to assess the reduction in entropy
knowledge of one variable provides about another, are closely related to
Granger causality <span class="citation" data-cites="schreiber2000measuring barnett2009granger">(Schreiber 2000;
Barnett, Barrett, and Seth 2009)</span>. The <em>transfer entropy</em>
<span class="math inline">\(T_{X \to Y}(t) = I(Y_t \colon X_{&lt;t} \mid
Y_{&lt;t})\)</span> extends this notion to time series by measuring the
amount of information present in <span class="math inline">\(Y_t\)</span> that is not contained in the past of
either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> (denoted <span class="math inline">\(X_{&lt;t}\)</span> and <span class="math inline">\(Y_{&lt;t}\)</span>) <span class="citation" data-cites="bossomaier2016transfer">(Bossomaier et al. 2016)</span>.
Using transfer entropy as a measure of causal interaction requires
accounting for potential confounding variables; the <em>conditional
transfer entropy</em> <span class="math inline">\(T_{X \to Y \mid Z}(t)
= I(Y_t \colon X_{&lt;t} \mid Y_{&lt;t}, Z_{&lt;t})\)</span> conditions
on the past of other variables to account for their potential
confounding influence <code>Sec.~4.2.3</code> <span class="citation" data-cites="bossomaier2016transfer">(Bossomaier et al. 2016)</span>.
Conditional transfer entropy can thus be interpreted as the amount of
information present in <span class="math inline">\(Y\)</span> that is
not contained in the past of <span class="math inline">\(X\)</span>, the
past of <span class="math inline">\(Y\)</span>, or the past of other
variables <span class="math inline">\(Z\)</span>.</p>
<p>To quantify the strength of causal interactions,
information-theoretic and transfer-entropy-based methods typically
require knowledge of the ground truth causal relationships that exist
<span class="citation" data-cites="janzing2013quantifying">(Janzing et
al. 2013)</span> or an ability to perturb the system <span class="citation" data-cites="ay2008information lizier2010differentiating">(Ay and Polani
2008; Lizier and Prokopenko 2010)</span>. In practice, these quantities
are typically interpreted as &#x201C;information transfer,&#x201D; and a variety of
estimation strategies and methods to automatically select the
conditioning set (i.e., the variables and time lags that should be
conditioned on) are used (e.g., <span class="citation" data-cites="shorten2021estimating">(Shorten, Spinney, and Lizier
2021)</span>). Multivariate conditional transfer entropy approaches
using various variable selection schemes can differentiate between
direct interactions, indirect interactions, and common causes, but their
results depend on choices such as the binning strategies used to
discretize continuous signals, the specific statistical tests used, and
the estimator used to compute transfer entropy <span class="citation" data-cites="wibral2014directed">(Wibral, Vicente, and Lizier
2014)</span>.
<code>[If we end up making the jump to IDTxl in our results: In our empirical results using transfer-entropy-based notions of directional influence we use the IDTxl toolbox [@wollstadt2019idtxl].]</code>
However, despite their mathematical differences, previous work has found
that cross-correlation-based metrics and information-based metrics tend
to produce qualitatively similar results, with similar patterns of true
and false positives <span class="citation" data-cites="garofalo2009evaluation">(Garofalo et al. 2009)</span>.</p>
<h2 id="interventions-in-neuroscience-causal-inference">Interventions in
neuroscience &amp; causal inference</h2>
<p>Data collected from experimental settings can provide more
inferential power than observational data alone. For example, consider
an experimentalist who is considering multiple causal hypotheses for two
nodes under study, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>: the hypothesis that <span class="math inline">\(x\)</span> is driving <span class="math inline">\(y\)</span>, the hypothesis that <span class="math inline">\(y\)</span> is driving <span class="math inline">\(x\)</span>, or the hypothesis that the two
variables are being independently driven by a hidden confounder.
Observational data revealing that <span class="math inline">\(x\)</span>
and <span class="math inline">\(y\)</span> produce correlated
time-series data is equally consistent with each of these three causal
hypotheses, providing the experimentalist with no inferential power.
Experimentally manipulating <span class="math inline">\(x\)</span> and
observing the output of <span class="math inline">\(y\)</span>, however,
allows the scientist to begin to establish which causal interaction
pattern is at work. Consistent with intuition from neuroscience
literature, a rich theoretical literature has described the central role
of interventions in inferring causal structure from data <span class="citation" data-cites="pearl2009causality eberhardt2007interventions">(Pearl 2009;
Eberhardt and Scheines 2007)</span>.</p>
<p><img src="figures/core_figure_sketches/figure1_sketch.png" title="role of interventions"></p>
<blockquote>
<p><strong>Figure INTRO:</strong> Examples of the roles interventions
have played in neuroscience. (A) <em>Passive observation</em> does not
involve stimulating the brain. In this example, passive observational
data is used to identify patients suffering from absence seizures. (B)
<em>Open-loop stimulation</em> involves recording activity in the brain
after perturbing a region with a known input signal. Using systematic
<em>open-loop stimulation experiments</em>, Penfield uncovered the
spatial organization of how senses and movement are mapped in the cortex
<span class="citation" data-cites="penfield1937somatic penfield1950cerebral">(W. Penfield and
Boldrey 1937 ; Wilder Penfield and Rasmussen 1950)</span>. (C)
<em>Closed-loop control</em> uses feedback control to precisely specify
activity in certain brain regions regardless of activity in other
regions. Using closed-loop control, <code>&lt;...&gt;</code>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</blockquote>
<p>The inferential power of interventions is depends on <em>where</em>
stimulation is applied: interventions on some portions of a system may
provide more information about the system&#x2019;s causal structure than
interventions in other areas. And interventions are also more valuable
when they more effectively set the state of the system: &#x201C;perfect&#x201D;
closed-loop control, which completely severs a node&#x2019;s activity from its
inputs, are often more informative than &#x201C;soft&#x201D; interventions that only
partially control a part of the system <span class="citation" data-cites="eberhardt2007interventions">(Eberhardt and Scheines
2007)</span>.</p>
<p>In experimental neuroscience settings, experimenters are faced with
deciding between interventions that differ in both location and
effectiveness. For example, stimulation can often only be applied to
certain regions of the brain. And while experimenters may be able to
exactly manipulate activity in some parts of the brain using closed-loop
control, in other locations it may only be possible to apply weaker
forms of intervention that perturb a region but do not manipulate its
activity exactly to a desired state. In Section <code>X</code>, we
compare the effectiveness of open-loop, closed-loop, and
partially-effective closed-loop control.</p>
<p>Although algorithms designed to choose optimal interventions are
often designed for simple models with strong assumptions,<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>
they provide intuition that can aid practitioners seeking to design
real-world experiments that provide as much scientific insight as
possible.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Importantly, the informativeness of
interventions is often independent of the algorithm used to infer causal
connections, meaning that certain interventions can reveal portions of a
circuit&#x2019;s causal structure that would be impossible for <em>any</em>
algorithm to infer from only observational data [<span class="citation" data-cites="das2020systematic">Das and Fiete (2020)</span>]<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. We similarly expect the results we
demonstrate in this paper to both inform experimentalists and open
avenues for further research.</p>
<h2 id="representations-reachability-minimal-dupe">Representations &amp;
reachability (minimal, dupe)</h2>
<pre class="text language-text" data-role="codeBlock" data-info="text">consider:
@ import &quot;/section_content/representation_reach.md&quot;
@ import &quot;/section_content/background_id_demo.md&quot;</pre>
<h1 id="results">Results</h1>
<p><img src="figures/core_figure_sketches/circuit_walkthrough_3circuits_key_sketch.png" title="generated by /code/fig_circuit_walkthrough.py"></p>
<blockquote>
<p><strong>Figure DEMO <em>(box format)</em>: Applying CLINC to
distinguish a pair of circuits</strong></p>
<p>Consider the three-node identification problem shown in the figure
above, in which the experimenter has identified three hypotheses for the
causal structure of the circuit. These circuit hypotheses, shown as
directed graphs in column 1, can each also be represented by an
adjacency matrix of the form \ref{eq:adjacency-matrix}: for example,
circuit A is represented by an adjacency matrix in which <span class="math inline">\(w_{01}\)</span>, <span class="math inline">\(w_{20}\)</span>, and <span class="math inline">\(w_{21} \neq 0\)</span>. Note that hypotheses A and
C have direct connections between nodes 0 and 2; while hypothesis B does
not have a direct connection between these nodes, computing the weighted
reachability matrix <span class="math inline">\(\widetilde{W}\)</span>
in circuit B an <em>indirect</em> connection exists through the path 2
<span class="math inline">\(\to\)</span> 1 <span class="math inline">\(\to\)</span> 0 (illustrated in gray in column
2).</p>
<p>Because there are direct or indirect connections between each pair of
nodes, passive observation of each hypothesized circuit would reveal
that each pair of nodes is correlated (column 3). These three hypotheses
are therefore difficult to distinguish<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> for
an experimentalist who performs only passive observation, but can be
distinguished through stimulation.</p>
<p>Column 4 shows the impact on observed correlations of performing
<em>open-loop</em> control on node 1. In hypothesis A, node 1 is not a
driver of other nodes, so open-loop stimulation at this site will not
increase the correlation between the signal observed at node 1 and other
nodes. The path from node 1 to 0 in hypotheses B and C, meanwhile,
causes the open-loop stimulation at node 1 to <em>increase</em> the
observed correlation between nodes 1 and 0. An experimenter can thus
distinguish between hypothesis A and the other two hypotheses by appling
open-loop control and observing the resulting pattern of correlations
(column 4). However, this pattern of open-loop stimulation would not
allow the experimenter to distinguish between hypotheses B and C.</p>
<p><em>Closed-loop</em> control (columns 5 and 6) can provide the
experimenter with even more inferential power. Column 5 shows the
resulting adjacency matrix when this closed-loop control is applied to
node 1. In each hypothesis, the impact of this closed-loop control is to
remove the impact of other nodes on node 1, because when perfect
closed-loop is applied the activity of node 1 is completely independent
of other nodes. (These severed connections are depicted in column 5 by
dashed lines.) In hypothesis B, this also results in the elimation of
the indirect connection from node 2 to node 1. The application of
closed-loop control at node 1 thus results in a different observed
correlation structure in each of the three circuit hypotheses (column
6). This means that the experimenter can therefore distinguish between
these circuit hypotheses by applying closed-loop control &#x2013; a task not
possible with passive observation or open-loop control.</p>
</blockquote>
<details>
<summary>
&#x21AA; figure to do items for <span class="citation" data-cites="Adam"><span>&#x201C;Adam-to-Do&#x201D;</span> (2022)</span>
</summary>
<ul class="task-list">
<li><input type="checkbox" disabled>
TODO: overall this needs to be cut from the caption and filtered into
the text body</li>
<li><input type="checkbox" disabled>
<span class="citation" data-cites="Adam"><span>&#x201C;Adam-to-Do&#x201D;</span>
(2022)</span> - change labels at top from &#x201C;B&#x201D; to &#x201C;1&#x201D;</li>
<li><input type="checkbox" disabled>
<span class="citation" data-cites="Adam"><span>&#x201C;Adam-to-Do&#x201D;</span>
(2022)</span> - add (A) (B) (C) labels to each row</li>
<li><input type="checkbox" disabled>
<span class="citation" data-cites="Adam"><span>&#x201C;Adam-to-Do&#x201D;</span>
(2022)</span> - in legend, change in/direct &#x201C;edge&#x201D; to in/direct
&#x201C;connection&#x201D;</li>
<li><input type="checkbox" disabled>
<span class="citation" data-cites="Adam"><span>&#x201C;Adam-to-Do&#x201D;</span>
(2022)</span> - in legend, orange dashed arrow to dark gray</li>
</ul>
</details>
<details>
<summary>
&#x21AA;2,3 circuit versions, straight from code
</summary>
<p><img src="code/network_analysis/results/circuit_walkthrough_2circuits.png" title="generated by /code/fig_circuit_walkthrough.py"> <img src="code/network_analysis/results/circuit_walkthrough_3circuits.png" title="generated by /code/fig_circuit_walkthrough.py"> &gt; 3 circuit
walkthrough, walkthrough will all intervention locations might be
appropriate for the supplement</p>
</details>
<details>
<summary>
&#x21AA;to do items
</summary>
<ul class="task-list">
<li><input type="checkbox" disabled>
find and include frequent circuit (curto + motif)</li>
<li><input type="checkbox" disabled>
wrap circuits we want in <code>example_circuits.py</code></li>
<li><input type="checkbox" disabled>
alt method of displaying indirect paths?<ul>
<li>https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.simple_paths.all_simple_paths.html#networkx.algorithms.simple_paths.all_simple_paths</li>
</ul></li>
</ul>
</details>
<details>
<summary>
&#x21AA;see also
</summary>
<p>more inspiration: - Combining multiple functional connectivity
methods to improve causal inferences - Advancing functional connectivity
research from association to causation - Fig1. of &#x201C;Systematic errors in
connectivity&#x201D;</p>
<p><img src="code/network_analysis/results/effect_of_control_horiz.png"> <img src="figures/misc_figure_sketches/two_circuit_case_study_mockup.png"></p>
<blockquote>
<p>this figure does a great job of: - setting up a key - incrementally
adding confounds - highlighting severed edges this figure does NOT -
explicitly address mutliple hypotheses</p>
</blockquote>
<p><img src="figures/misc_figure_sketches/closed_loop_severs_inputs.png">
<strong>Figure 11: Closed-loop control compensates for inputs to a node
in simple circuits:</strong> The left column shows a simple circuit and
recording and stimulation sites for an open-loop experiment. The right
column shows the functional circuit which results from closed-loop
control of the output of region A. Generally, assuming perfectly
effective control, the impact of other inputs to a controlled node is
nullified and therefore crossed off the functional circuit diagram.</p>
<blockquote>
<p>this figure does a great job of: - using a minimal version of the key
above - showing two competing hypotheses - (throughs latent / common
modulation in for fun)</p>
</blockquote>
<img src="figures/misc_figure_sketches/closed_loop_distinguishes_corticalEI.png">
<strong>Figure 12: Closed-loop control allows for two circuit hypotheses
to be distinguished.</strong> Two hypothesized circuits for the
relationships between pyramidal (Pyr, excitatory), parvalbumin-positive
(PV, inhibitory), and somatostain-expressing (Som, inhibitory) cells are
shown in the two rows. Dashed lines in the right column represent
connections whose effects are compensated for through closed-loop
control of the Pyr node. By measuring correlations between recorded
regions during closed-loop control it is possible to distinguish which
hypothesized circuit better matches the data. Notably in the open-loop
intervention, activity in all regions is correlated for both
hypothesized circuits leading to ambiguity.
</details>
<details>
<summary>
&#x21AA;more notes
</summary>
<p>probably want - two circuits which look clearly different - ! but
which have equivalent reachability - possibly with reciprocal
connections - possssibly with common modulation</p>
<ul>
<li><p>do we need to reflect back from set of possible observations to
consistent hypotheses?</p>
<ul>
<li>mention markov equivalence classes explicitly?</li>
</ul></li>
<li><p>intuitive explanation using binary reachability rules
<!-- - consider postponing until we introduce intervention?
  - i.e. have one figure that walks through both reachability and impact of intervention --></p></li>
<li><p><em>point to the rest of the paper as deepening and generalizing
these ideas</em></p></li>
<li><p><em>(example papers - Advancing functional connectivity research
from association to causation, Combining multiple functional
connectivity methods to improve causal inferences)</em></p></li>
<li><p>connect <strong>graded reachability</strong> to ID-SNR</p>
<ul>
<li><span class="math inline">\(\mathrm{IDSNR}_{ij}\)</span> measures
the strength of signal related to the connection <span class="math inline">\(i&#x2192;j\)</span> relative to in the output of node
<span class="math inline">\(j\)</span></li>
<li>for true, direct connections this quantity increasing means a (true
positive) connection will be identified more easily (with high
certainty, requiring less data)</li>
<li>for false or indirect connections, this quantity increasing means a
false positive connection is more likely to be identified</li>
<li>as a result we want to maximize IDSNR for true links, and minimize
it for false/indirect links</li>
</ul></li>
</ul>
<p>( see also
<code>sketches_and_notation/walkthrough_EI_dissection.md</code> )</p>
</details>
<p><code>reference extended methods</code></p>
<pre class="text language-text" data-role="codeBlock" data-info="text">extract minimum from:
@ import 
&quot;/section_content/methods_simulations.md&quot; 
</pre>
<ul>
<li><code>reference extended methods</code></li>
</ul>
<pre class="text language-text" data-role="codeBlock" data-info="text">extract minimum from:
@ import &quot;/section_content/methods_simulations.md&quot; </pre>
<h2 id="steps-of-inference-overview-of-clinc-approach">Steps of
inference - <em>overview of CLINC approach</em> (+)</h2>
<p><img src="figures/core_figure_sketches/methods_overview_pipeline_sketch.png"></p>
<blockquote>
<p><strong>Figure OVERVIEW:</strong> &#x2026;</p>
</blockquote>
<blockquote>
<p><strong>Theme B.</strong> Experiments for circuit inference can be
thought of as <strong>narrowing the set of plausible
explanations</strong>, refining a hypotheses space<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
</blockquote>
<p><strong>We envision the structure of an experiment<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></strong> to include the following
broad stages:</p>
<ol type="1">
<li>First, explicitly <strong>enumerate the set of hypothesized
circuits.</strong> Hypotheses about the structure of the circuit would
be based on multiple sources of information including prior recordings,
anatomical constraints revealed by
<code>experiments where you look at the fiber bundles connecting regions</code>,
or commonly observed connectivity patterns in other systems
<code>[&#x1F6A7; add other sources of priors for circuit hypotheses]</code>[^bonus_causal][^more_assumptions]
These hypotheses should be expressed as a set of circuits (adjacency
matrices) each with a probability representing the prior belief about
the relative likelihood of these options. This hypothesis set can be
thought of as a space of possible explanations for the observed data so
far, which will be narrowed down through further intervention,
observation, and inference. <a href="#fig-disambig">(Fig.DISAMBIG top
row)</a></li>
</ol>
<ol start="2" type="1">
<li>Second, <em>in silico</em>, <strong>forecast patterns of
correlation</strong> which could result from applying candidate
interventions. Most algorithms<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> for circuit inference
quantify and threshold measures of dependence between pairs of nodes.
Correlations are often used to measure the linear component of
dependence between outputs of two nodes, although the approach described
here should generalize to other nonlinear measures of dependence such as
mutual information. As such, the observed pattern of dependence
(correlations) in a given experiment summarizes the input to an
inference procedure to recover an estimated circuit.<br>
&#xA0;&#xA0;&#xA0;&#xA0;A detailed forecast of the observed outputs could be achieved by
simulating biophysical networks across candidate interventions and
hypothesized ground-truth circuits. However, for large networks or large
hypothesis sets this may be expensive to compute. Instead, for the sake
of rapid iteration in designing interventions, we propose using the
reachability representation of a linear (linearized) network to
succinctly and efficiently predict the observed correlations<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> across nodes[^node_repr]. The
methods described in <code>[ref. prediction methods]</code> allow us to
anticipate how open and closed-loop interventions across nodes in the
network might increase, decrease, or sever dependencies between node
outputs.</li>
</ol>
<ol start="3" type="1">
<li><code>{Survey / analyze / compare / summarize}</code>
<code>{diversity / equivalence /  distinguishability of}</code> patterns
of correlation across each hypothesized circuit. A useful experiment
(intervention) is one which produces highly distinct outcomes when
applied to each of the hypothesized circuits, while an experiment which
produces the same outcome across all hypothesized circuits would be
redundant. &#xA0;&#xA0;&#xA0;&#xA0;Before collecting experimental data we do not know the
ground-truth circuit with certainty, therefore it is useful to
understand the range of possible observed patterns of dependence. To
distill this range of possibilities to a make a decision about which
intervention to apply, it is also useful to summarize the expected
information we would gain about circuit identity across the range of
hypotheses. <a href="#fig-disambig">(across columns of Fig.DISAMBIG)</a>
&gt;-<em>Here we generalize across specific values of synaptic weights
and divide observed patterns into categories: increased correlation,
decreased correlation, no correlation.</em></li>
</ol>
<p>&#x1F6A7;
<code>Entropy as a measure of information about circuit hypotheses</code>
<strong><code>@ import &quot;/section_content/methods_entropy.md&quot;</code></strong></p>
<p><code>select intervention - (is this its own step, or the last part of step 3)</code>
Here, we describe a &#x201C;greedy&#x201D; approach for choosing an effective
single-node intervention, but extending the approach above to predict
joint entropy would allow a joint or sequential experimental design
which would be optimal over multiple interventions. &gt;- possible
interventions consist of open-loop and closed-loop stim at each of N
nodes &gt; - but more constraints on the set of interventions can easily
be incorporated at this stage</p>
<p>For selecting the first intervention type and location, we propose
choosing the intervention which results in the maximum expected circuit
information, that is: <span class="math display">\[S_i^* =
\underset{i}{\arg\max}\,H(C|S_i)\]</span><a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>&#x1F6A7; 4. Apply intervention and collect data Using entropy as a metric
to select a useful intervention, the next step is to conduct that
interventional experiment, in-vivo or in a detailed simulation. Such an
experiment may reveal outputs patterns not fully captured by the
linearized reachability representation.</p>
<p><code>[extract correlations ...]</code> <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</p>
<ol start="5" type="1">
<li><strong>Given the observed dependency pattern, form a posterior
belief over hypotheses</strong> <code>[&#x1F6A7; transition text]</code></li>
</ol>
<p><strong><code>@ import &quot;/section_content/methods_entropy_selection.md&quot;</code></strong></p>
<h3 id="intervening-provides-categorical-improvements-in-inference-power-beyond-passive-observation">Intervening
provides categorical improvements in inference power beyond passive
observation</h3>
<p>In the previous sections, we established how open-loop interventions
modify observed pairwise correlations, and how closed-loop interventions
modify a circuit&#x2019;s functional connectivity. Figure <code>ID-DEMO</code>
demonstrated a simple example of how removing connections in a circuit
can sometimes reveal more distinct patterns of dependence, and
distinguish hypotheses which are indistinguishable through passive
observation and open-loop control. Here, we systematize this approach to
choose an appropriate intervention to narrow down a hypothesis set. The
following sections will address how to evaluate the relative
effectiveness of a particular intervention. Multiple intervention types
and locations are compared for a larger circuit hypothesis set to build
towards general principles for where and how to intervene.</p>
<p>While the ground truth connectivity is rarely available during
experiments, it is valuable to explicitly lay out our prior hypothesis
in the form of a directed graph or adjacency matrix. Panel A of
<code>Fig. DISAMBIG</code> shows the adjacency and reachability of 6
candidate circuit hypotheses. <code>Row Ba</code> illustrates the
presence of pairwise correlation for each hypotheses under passive
observation. While the magnitudes of correlation will depend on
particular values of system parameters, here we focus on only the
presence or absence of a significant correlation between two nodes, as
well as whether correlations increase or decrease from their baseline.
In this way, we build towards an understanding of the categorical impact
of intervention on observed pairwise dependence, which should be general
across particular parameter values or algorithms for circuit inference.
<em>(More concrete, quantitative effects will be explored in the next
section).</em></p>
<p>The set of patterns of pairwise dependences across the hypothesis set
form an &#x201C;intervention-specific fingerprint&#x201D; (i.e.&#xA0;a single row of
<code>Fig. DISAMBIG</code>). This fingerprint summarizes the outcomes of
a particular experiment with intervention, and therefore shows which
hypotheses are observationally equivalent under this observation. If
this fingerprint contains many examples of the same pattern (such as the
all-to-all correlation pattern seen under passive observation,
<code>row Ba</code>), many different circuits correspond to the same
observation, and that experiment contributes low information to
distinguish between hypotheses. On the other hand, a maximally
informative experiment would result in unique observations corresponding
to each hypothesis. Observations from such an experiment would be
sufficient to narrow the inferred circuit down to a single
hypotheses.</p>
<p>To quantify this hypothesis ambiguity based on the diversity of a set
of possible outcomes, we compute the Shannon entropy over the
distribution of patterns (See Methods <a href="#methods-entropy">entropy</a>). Because our hypotheses set
contains circuits with relatively dense connectivity, 5 of the 6
hypotheses result in all-to-all correlations, with the final hypothesis
displaying a unique V-shaped pattern of correlation (A~B, and A~C,
<code>row Ba</code>). The entropy of this distribution is 0.65 bits. To
interpret this entropy value, it is useful to understand the maximum
achievable entropy, which is simply the logarithm of the number of
hypotheses. In this case, <span class="math inline">\(H_{max} =
\log_2(6)\approx 2.58 \text{bits}\)</span>, which indicates the
information gained from passive observation is 25% efficient
($H_{passive} / H_{max} \approx 0.25 $).</p>
<p>As discussed in section <a href>#</a>, high-variance open-loop
intervention tends to increase correlations between pairs of nodes
downstream of the intervention, and decreases correlations when only one
node is downstream of the stimulus location. This can produce more
distinct, hypothesis-specific patterns of pairwise dependence.
<code>Fig. DISAMBIG, row Bb</code> shows how open-loop intervention at
node A distinguishes hypotheses <span class="math inline">\(\{C_1,C_2,C_3\}\)</span> (where node A has
reachability to nodes B and C) from hypotheses <span class="math inline">\(\{C_4,C_5\}\)</span> (where node A can only reach
node C). This increased distinguishability is reflected in the
distribution of correlation patterns in the fingerprint, and the entropy
of that distribution <span class="math inline">\((H_{OL&#x2192;A} \approx 1.46
\text{bits}, H_{OL&#x2192;A}/H_{max} = 0.56)\)</span>. In expectation, this
intervention provides more information about the hypothesis set than
passive observation alone.</p>
<p>For some sets of circuit hypotheses, the capability of closed-loop
intervention to remove indirect connections uncovers distinct patterns
of resulting correlations that would otherwise be equivalent under other
interventions. Because <span class="math inline">\(C_4\)</span> and
<span class="math inline">\(C_5\)</span> have equivalent reachability
matrices, their pairwise correlations will be similar even under
open-loop intervention. But in <code>Row Bb</code>, closed-loop
intervention at node A, severs the inputs to this node. Under hypothesis
<span class="math inline">\(C_4\)</span>, nodes C and B remain
correlated through their direct connection, however, under <span class="math inline">\(C_5\)</span>, severing inputs to A also severs the
indirect influence of C on B, which is sufficient to remove the
correlation between nodes C and B. The distribution of observed patterns
<code>(Row Dc)</code>, contains more distinct entries, and leads to a
higher across-hypothesis entropy of <span class="math inline">\(H_{CL&#x2192;A}
\approx 1.79 \text{bits}, H_{CL&#x2192;A}/H_{max} = 0.69\)</span>.</p>
<p>This example highlighted a location for intervention where
closed-loop control provides a categorical for distinguishing circuit
hypotheses above open-loop control (and passive observation). This
advantage is notable, in that it represents an improvement in circuit
estimation bias which would be unlikely to be mitigated through
collecting more data. However, <code>Fig. DISAMBIG</code> further
highlights the importance of not only intervention <em>type</em>, but
also intervention <em>location</em> in determining successful circuit
inference. For a given intervention type, different locations for
delivering stimuli result in categorically different
hypothesis-narrowing information <em>(e.g.&#xA0;<span class="math inline">\(H(OL_B) &lt; H(OL_A) &lt; H(OL_C)\)</span>, Fig.
<code>DISAMBIG</code> Column D)</em>. On the other hand, for
interventions at nodes B and C, open-loop and closed-loop control result
in identical correlation fingerprints for this hypothesis set &#x2014;
closed-loop control at these locations does <em>not</em> provide a
categorical benefit beyond the information learned through open-loop
control. This equivalence between open-loop and closed-loop
interventions arises in cases where severing inputs at the target node
does not interrupt an indirect connection which otherwise makes circuits
in the hypothesis set ambiguous.</p>
<p>To summarize, by understanding the relationship between circuit
structure, the effect of interventions, and changes to the observed
patterns of correlation, we were able to demonstrate the relative
utility of passive observation, open-loop control, and closed-loop
control. Open-loop control improves the capacity to distinguish circuits
by increasing the diversity of outcomes as correlations increase or
decrease. In addition, closed-loop control is capable of providing a
categorical improvement in the ability to distinguish between and narrow
down a set of competing hypotheses. It results in distinct patterns of
observed dependence in additional cases even with equivalent
reachability by severing ambiguous indirect connections. These
categorical differences in across-circuit entropy are likely to reflect
fundamental differences in the best-case conditions for evaluating
similar hypotheses, regardless of data volume or algorithms used for
circuit inference.</p>
<p>However, the utility of a given intervention does depend strongly on
the location of control relative to paths in the hypothesized circuits.
Circuits and hypothesis sets where closed-loop is likely to outperform
open-loop control would consist of similar circuits, where direct and
indirect connections are difficult to distinguish, such as those with
recurrent loops. In highly sparse or largely-feedforward circuits,
open-loop and closed-loop intervention are likely to result in similar
circuit information.</p>
<p><a id="fig-disambig" href></a></p>
<p><img src="figures/core_figure_sketches/circuit_entropy_sketch.png"></p>
<blockquote>
<p><strong>Figure DISAMBIG: Interventions narrow the set of hypotheses
consistent with observed correlations</strong></p>
</blockquote>
<blockquote>
<p><strong>(A)</strong> Directed adjacency matrices represent the true
and hypothesized causal circuit structure. Directed reachability
matrices represent the direct <em>(black)</em> and indirect
<em>(grey)</em> influences in a network. Notably, different adjacency
matrices can have equivalent reachability matrices making distinguishing
between similar causal structures difficult, even with open-loop
control. <strong>(B)</strong> Correlations between pairs of nodes.
<strong>a)</strong> Under passive observation, the direction of
influence is difficult to ascertain. <strong>(B b-g)</strong> The impact
of open-loop intervention at each of the nodes in the network is
illustrated by modifications to the passive correlation pattern. Thick
orange<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> edges denote correlations which
increase above their baseline value with high variance open-loop input.
Thin blue edges denote correlations which decrease, often as a result of
increased connection-independent &#x201C;noise&#x201D; variance in one of the
participating nodes. Grey edges are unaffected by intervention at that
location. <strong>(C)</strong> Across-circuit entropy for each
intervention type and location. Grey lines correspond to a single
intervention location. Circle markers represent the mean entropy for a
given intervention type across all intervention locations. Green dotted
lines represents the maximum achievable entropy for this hypothesis set.
<strong>(D)</strong> Distributions of patterns of pairwise correlation
across hypotheses, for each intervention location and type.
Distributions with more observed patterns, and more uniform
probabilities correspond to experiments which reveal more information to
narrow the set of candidate hypotheses.</p>
</blockquote>
<pre class="text language-text" data-role="codeBlock" data-info="text">text for choosing an intervention ... </pre>
<p>While a primary advantage of closed-loop intervention for circuit
inference is its ability to functionally lesion indirect connections,
another, more nuanced advantage of closed-loop control lies in its
capacity to bidirectionally manipulate output variance. While the
variance of an open-loop stimulus can be titrated to adjust the output
variance at a node, in general, an open-loop stimulus cannot reduce this
variance below its intrinsic<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> variability. That is,
if the system is linear with Gaussian noise, each node&#x2019;s intrinsic
variability sets a lower bound on the total output variance of that node
in the presence of additive open-loop stimulation.</p>
<p><strong><code>@ import &quot;/section_content/methods_intervention_variance.md&quot;</code></strong></p>
<h3 id="impact-of-intervention-location-and-variance-on-pairwise-correlations">Impact
of intervention location and variance on pairwise correlations</h3>
<p><a href="methods1_predicting_correlation.md">related methods</a></p>
<p>We have shown that closed-loop interventions provide more flexible
control over output variance of nodes in a network, and that shared and
independent sources of variance determine pairwise correlations between
node outputs. Together, this suggests closed-loop interventions may
allow us to shape pairwise correlations across a circuit with more
degrees of freedom<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>, which may result in more effective
circuit inference.</p>
<p>One application of this increased flexibility is to increase
correlations associated with pairs of directly correlated nodes, while
decreasing spurious correlations associated with pairs of nodes without
a direct connection (but perhaps are influenced by a common input, or
are connected only indirectly). Such an approach would effectively
increase the &#x201C;signal-to-noise ratio&#x201D; of causal, connection-related
signal in the observed correlations. While &#x201C;correlation does not imply
causation,&#x201D; intervention may decrease the gap between the two.</p>
<p>Our hypothesis is that this shaping of pairwise correlations will
result in reduced false positive edges in inferred circuits,
&#x201C;un-blurring&#x201D; the indirect associations that would otherwise confound
circuit inference. However care must be taken, as this strategy relies
on a hypothesis for the ground truth adjacency and may also result in a
&#x201C;confirmation bias&#x201D; as new spurious correlations can be introduced
through closed-loop intervention.</p>
<p><a id="fig-predict" href></a></p>
<p><img src="figures/from_code/bidirectional_correlation.png" title="generated by sweep_gaussian_SNR.py"></p>
<p>&#x1F6A7; <strong>Figure VAR: Location, variance, and type of intervention
shape pairwise correlations</strong> <strong>(CENTER)</strong> A
two-node linear Gaussian network is simulated with a connection from A
to B. Open-loop interventions <em>(blue)</em> consist of independent
Gaussian inputs with a range of variances <span class="math inline">\(\sigma^2_S\)</span>. Closed-loop interventions
<em>(orange)</em> consist of feedback control with time-varying target
drawn from an an independent Gaussian with a range of variances.
Incomplete closed-loop interventions result in node outputs which are a
mix of the control target and network-driven activity.</p>
<p><strong>(left)</strong> Intervention &#x201C;upstream&#x201D; of the connection A&#x2192;B
increases the correlation <span class="math inline">\(r^2(A,B)\)</span>.
<strong>(right)</strong> Intervention at the terminal of the connection
A&#x2192;B decreases the correlation <span class="math inline">\(r^2(A,B)\)</span> by adding connection-independent
noise. <strong>(somewhere)</strong> Intervention with shared inputs to
both nodes generally increases <span class="math inline">\(r^2(A,B)\)</span>, <em>(even without a connection
from A to B, see Methods <a href="REF-SECTION_HERE">#</a>)</em>.</p>
<p><code>LEAD in, discussing figure</code></p>
<p><code>dicsussing coreach sign</code></p>
<p>&#x1F6A7; The change in correlation as a function of changing intervention
variance (<span class="math inline">\(\frac{dr^2_{ij}}{dS}\)</span>) can
therefore be used as an additional indicator of presence/absence and
directionality of the connection between A,B <em>(see <a href="fig-disambig">fig.&#xA0;disambig. D.)</a>)</em> &#x1F6A7;</p>
<p><strong><code>@ import &quot;/section_content/methods_coreach_sign.md&quot;</code></strong></p>
<p><a href="#fig-var">Fig. variance</a> also demonstrates the relative
dynamic range of correlations achievable under passive observation,
open-, and closed-loop intervention. In the passive case, correlations
are determined by intrinsic properties of the network such as network
weights and intrinsic node variances.
<!--"These properties have influence over the observed correlations in a way that can be difficult to separate from differences due to the ground-truth circuit." -- not sure what this part means-->
With open-loop intervention, the impact of increasing variance at a
particular node can be observed, but the dynamic range of achievable
correlations is bounded by being unable to reduce variance below its
baseline level. With closed-loop control, the bidirectional manipulation
of the output variance for a node means a much wider range of
correlations can be achieved <a href="#fig-var">(blue v.s. orange in
fig.&#xA0;variance)</a>, resulting in a more sensitive signal reflecting the
ground-truth connectivity.</p>
<p>Closed-loop interventions <em>(orange)</em> generally result in
larger changes in correlation across <span class="math inline">\(\sigma^2_S\)</span> than the equivalent open-loop
intervention. Closed-loop control at B effectively lesions the
connection A&#x2192;B, resulting in near-zero correlation.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<pre class="text language-text" data-role="codeBlock" data-info="text">DISCUSS PARTIAL CONTROL
- /section_content/methods_interventions.md
- unclear at the outset, will partial closed-loop control have any properties of ideal closed-loop control? or will partial rejection of disturbances break the impact? 
- result: generally falls between open and closed-loop
  - &quot;mostly&quot; effective closed-loop control is still worth pursuing</pre>
<pre class="text language-text" data-role="codeBlock" data-info="text">FUNNEL OUT
- summarize implications 
- either hint towards or away from followup analysis to identifiability</pre>
<details>
<summary>
&#x21AA;Notes from matt
</summary>
<!-- - [super minor] First part of fig DISAMBIG: subsections (A) through (C) work really well
- [super minor] in caption for (D-F): "modifications to the passive correlation pattern" is a bit confusing in the context of open-loop intervention
- [super minor] also in caption for (D-F): really like "intervention-specific fingerprint" terminology. The last sentence of the (D-F) caption really hits the message home, possible to emphasize that this is the take-home message earlier?
- [narrative/organization] fig DISAMBIG feels really example-y, more like a proof of concept than 'results.' The writing in Sec 5.1.1 also has this flavor, like it could be in a methods section. (The plot in the top right feels much more results-ey.) Not necessarily a bad thing, maybe just a consideration for thinking about article vs perspective flavor. -->
<ul>
<li>[missing] Section 5.1.2.1: what are the definitions of S_k,
CoReach(i,j|S_k), and R_{ij}?</li>
<li>[narrative] Section 5.1.2.1: the narrative here really works for me,
but it&#x2019;s a little unclear whether this is more of a &#x2018;result&#x2019; or a
&#x2018;recipe&#x2019; &#x2013; the figures here also feel more example/proof-of-concept-ey,
and the math here helps ground things in</li>
<li>[missing] discussion of partial closed-loop control?</li>
</ul>
</details>
<h1 id="discussion">Discussion</h1>
<pre class="text language-text" data-role="codeBlock" data-info="text">Restate themes!
- narrowing search space 
- where you intervene matters</pre>
<h3 id="limitations">limitations</h3>
<p>The examples explored in this work simplify several key features that
may have relevant contributions to circuit identification in practical
experiments. [&#x2026;]</p>
<p><code>full observability</code></p>
<h3 id="results-summary-summary-of-value-closed-loop-generally">results
summary &#x2192; summary of value closed-loop generally</h3>
<p>Closed-loop control has the disadvantages of being more complex to
implement and requires specialized real-time hardware and software,
however it has been shown to have multifaceted usefulness in clinical
and basic science applications. Here we focused on two advantages in
particular; First, the capacity for functional lesioning which
(reversibly) severs inputs to nodes and second, closed-loop control&#x2019;s
capacity to precisely shape variance across nodes. Both of these
advantages facilitate opportunities for closed-loop intervention to
reveal more circuit structure than passive observation or even open-loop
experiments.</p>
<h3 id="summary-of-guidelines-for-experimenters">summary of guidelines
for experimenters</h3>
<p>In studying the utility of various intervention for circuit inference
we arrived at a few general guidelines which may assist experimental
neuroscientists in designing the right intervention for the quesiton at
hand. First, more ambiguous hypotheses sets require &#x201C;stronger&#x201D;
interventions to distinguish. Open-loop intervention may be sufficient
to determine directionality of functional relationships, but as larger
numbers of similar hypotheses [&#x2026;] closed-loop intervention reduces the
hypothesis set more efficiently. Second, we find that dense networks
with strong reciprocal connections tend to result in many equivalent
circuit hypotheses, but that well-placed closed-loop control can disrupt
loops and simplify correlation structure to be more identifiable.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> Recurrent loops are a common
feature of neural circuit, and represent key opportunities for
successful closed-loop intervention. The same is true for circuits with
strong indirect correlations</p>
<p><code>hidden confounds</code></p>
<h3 id="funnel-out-future-work-broad-impact">&#x201C;funnel out&#x201D;, future work &#x2192;
broad impact</h3>
<p><code>sequential experimental design</code></p>
<p><em>see <a href="sketches_and_notation/discussion/limitations_future_work.md">limitations_future_work.md</a></em></p>
<h1 id="methods">Methods</h1>
<h2 id="modeling-network-structure-and-dynamics-41-simulation-methods">Modeling
network structure and dynamics (4.1) &#x2014; Simulation Methods</h2>
<h2 id="modeling-network-structure-and-dynamics">Modeling network
structure and dynamics</h2>
<p>We sought to understand both general principles (abstracted across
particulars of network implementation) as well as some practical
considerations introduced by dealing with spikes and synapses.</p>
<h3 id="stochastic-network-dynamics">Stochastic network dynamics</h3>
<p>The first approach is accomplished with a network of nodes with
Gaussian noise sources, linear interactions, and linear dynamics. The
second approach is achieved with a network of nodes consisting of
populations of leaky integrate-and-fire (LIF) neurons. These differ from
the simpler case in their nonlinear-outputs, arising from inclusion of a
spiking threshold. Interactions between neurons happen through spiking
synapses, meaning information is passed between neurons sparsely in
time<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>.</p>
<p><em>Neuron dynamics:</em> <span class="math display">\[
\frac{dV}{dt} = \frac{V_0 + I - V}{\tau_m} + \sigma_m \sqrt{\tau_m}
\xi(t)
\]</span></p>
<h3 id="time-resolvable-interactions">Time-resolvable interactions</h3>
<p>Additionally we study two domains of interactions between
populations; contemporaneous and delay-resolvable connections. These
domains represent the relative timescales of measurement versus
timescale of synaptic delay. <a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<p>In the delay-resolvable domain, directionality of connections may be
inferred even under passive observations by looking at temporal
precedence - whether the past of one signal is more strongly correlated
with future lags of another signal <em>(i.e.&#xA0;cross-correlation)</em>. In
the contemporaneous domain, network influences act within the time of a
single sample<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a> so this temporal precedence clue is
lost (although directionality can still be inferred in the presence of
intervention).</p>
<p>The following work is presented with the linear Gaussian and
contemporaneous domains as the default for simplicity and
conciseness.</p>
<details>
<summary>
&#x21AA;concept figures
</summary>
<p><img src="figures/whiteboard/concept_time_resolved.png"> <img src="figures/whiteboard/concept_open_loop_contemporaneous.png"></p>
</details>
<h3 id="code-implementation">Code implementation</h3>
<p>Software for data generation, analysis, and plotting is available at
https://github.com/awillats/clinc. Both linear Gaussian and spiking
networks are simulated with code built from the <a href="https://elifesciences.org/articles/47314">Brian2</a> spiking
neural network simulator. This allows for highly modular code with
easily interchanged neuron models and standardized output preprocessing
and plotting. It was necessary to write an additional custom extension
to Brian2 in order to capture delayed linear Gaussian interactions,
available at <a href="https://github.com/awillats/brian_delayed_gaussian">brian_delayed_gaussian</a>.
With this added functionality, it is possible to compare the equivalent
network parameters only changing linear Gaussian versus spiking dynamics
and inspect differences solely due to spiking.</p>
<p><em>see <a href="_network_parameters_table.md">_network_parameters_table.md</a> for
list of relevant parameters</em></p>
<h3 id="stochastic-network-dynamics-411">Stochastic network dynamics
(4.1.1)</h3>
<h3 id="delayed-interactions-412">Delayed interactions (4.1.2)</h3>
<h3 id="code-implementation-413">Code implementation (4.1.3)</h3>
<h2 id="implementing-interventions-42">Implementing interventions
(4.2)</h2>
<h2 id="implementing-interventions">Implementing interventions</h2>
<p>To study the effect of various interventions we simulated inputs to
nodes in a network. In the <strong>passive setting</strong>, nodes
receive additive drive from <em>private</em> Gaussian noise sources
common to all neurons within a node, but independent across nodes. The
variance of this noise is specified by <span class="math inline">\(\sigma_m \sqrt{\tau_m}\)</span>.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></p>
<p><code>for the case of leaky integrate and fire neurons:</code> <span class="math display">\[
\frac{dV}{dt} = \frac{V_0 + I - V}{\tau_m} + \sigma_m \sqrt{\tau_m}
\xi(t)
\]</span></p>
<p>To emulate <strong>open-loop intervention</strong> we simulated
current injection from an external source. This is intended to represent
experiments involving stimulation from microelectrodes or optogenetics
<em>(albeit simplifying away any impact of actuator dynamics)</em>. By
default, open-loop intervention is specified as white noise sampled at
each timestep from a Gaussian distribution with mean and variance <span class="math inline">\(\mu_{intv.}\)</span> and <span class="math inline">\(\sigma^2_{intv.}\)</span><a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></p>
<p><span class="math display">\[
I_{open-loop} \sim \mathcal{N}(\mu_{intv.},\,\sigma^{2}_{intv.})\\
\]</span> Ignoring the effect of signal means in the linear Gaussian
setting: <span class="math display">\[
X_k = f(\sigma^2_m, \sigma^{2}_{intv.})
\]</span> <code>per-node indexing needs resolving here also</code></p>
<p>Ideal <strong>closed-loop control</strong> is able to overwrite the
output of a node, setting it precisely to the specified target <span class="math inline">\(T\)</span>. <span class="math display">\[
\begin{aligned}
T &amp;\sim \mathcal{N}(\mu_{intv.},\,\sigma^{2}_{intv.}) \\
I_{closed-loop} &amp;= f(X, T)  \\
X_k | CL_{k} &amp;\approx T
\end{aligned}
\]</span> Note that in this setting, the <em>output</em> of a node <span class="math inline">\(X_k\)</span> under closed-loop control is
identical to the target, therefore <span class="math display">\[
X_k | CL_{k} = f(\sigma^{2}_{intv.}) \perp \sigma^2_m
\]</span> In practice, near-ideal control is only possible with very
fast measurement and computation relative to the network&#x2019;s intrinsic
dynamics, such as in the case of dynamic clamp<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>.
To demonstrate a broader class of closed-loop interventions (such as
those achievable with extracellular recording and stimulation),
imperfect &#x201C;partial&#x201D; control is simulated by linearly interpolating the
output of each node between the target <span class="math inline">\(T\)</span> and the uncontrolled output based on a
control effectiveness parameter <span class="math inline">\(\gamma\)</span></p>
<p><span class="math display">\[
X | CL_{k, \gamma} = \gamma T + (1-\gamma) X
\]</span></p>
<details>
<summary>
&#x21AA;out of scope: full-loop discrete-time simulation
</summary>
<p>In the full discrete-time simulation, closed-loop interventions are
instead simulated through a proportional-integral-derivative (PID)
control policy with control efficacy determined functionally by the
strength of controller gains <span class="math inline">\(K = \{k_P, k_I,
k_D\}\)</span> relative to the dynamics of the network.</p>
<p><span class="math display">\[I_{PID} = \text{PID}(X,T|
K)\]</span></p>
<p>Another interesting intervention to study is <strong>open-loop replay
of a closed-loop stimulus</strong>, <em>that is</em> taking a particular
injected current <span class="math inline">\(I_{CL,\,prev}\)</span> used
to drive nodes to a target <span class="math inline">\(T_{prev}\)</span>
and adding it back to the network in a separate trial.</p>
<p>Because the instantiation of noise in the network will be different
from trial to trial, this &#x201C;replay&#x201D; stimulus will no longer adapt
sample-by-sample (therefore it should be considered open-loop) and the
node&#x2019;s output cannot be expected to match the target precisely, however
the statistics of externally applied inputs will be the same. In effect,
the comparison between closed-loop and open-loop replay conditions
reveals the specific effect of feedback intervention while controlling
for any confounds from input statistics.</p>
</details>
<h2 id="predicting-correlation-structure-31-theory-prediction">Predicting
correlation structure (3.1) &#x2014; Theory / Prediction</h2>
<h3 id="representations-reachability-23">Representations &amp;
reachability (2.3?)</h3>
<p>Different mathematical representations of circuits can elucidate
different connectivity properties. For example, consider the circuit
<span class="math inline">\(A \rightarrow B \leftarrow C\)</span>. This
circuit can be modeled by the dynamical system <span class="math display">\[
\begin{cases}
\dot{x}_A &amp;= f_A(e_A) \\
\dot{x}_B &amp;= f_B(x_A, x_C, e_B) \\
\dot{x}_C &amp;= f_C(e_C),
\end{cases}
\]</span> where <span class="math inline">\(e_A\)</span>, <span class="math inline">\(e_B\)</span>, and <span class="math inline">\(e_C\)</span> represent exogenous inputs that are
inputs from other variables and each other<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>.</p>
<p>When the system is linear we can use matrix notation to describe the
impact of each node on the others:<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> <span class="math display">\[
x_{t+1} = W x_t + e_t,
\]</span> where <span class="math inline">\(x_t \in
\mathbb{R}^p\)</span> denotes the state of each of the <span class="math inline">\(p\)</span> nodes at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(e_t
\in \mathbb{R}^p\)</span> denotes the instantiation of each node&#x2019;s
(independent and identically-distributed) private noise variance at time
<span class="math inline">\(t\)</span>.</p>
<p>where <span class="math inline">\(W\)</span> represents the
<em>adjacency matrix</em> <span class="math display">\[
W = \begin{bmatrix}
    w_{AA} &amp; w_{AB} &amp; w_{AC} \\
    w_{BA} &amp; w_{BB} &amp; w_{BC} \\
    w_{CA} &amp; w_{CB} &amp; w_{CC}
\end{bmatrix}.
\]</span> In the circuit <span class="math inline">\(A \rightarrow B
\leftarrow C\)</span>, we would have <span class="math inline">\(w_{AB}
\neq 0\)</span> and <span class="math inline">\(w_{CB} \neq
0\)</span>.</p>
<p>The adjacency matrix captures directional first-order connections in
the circuit: <span class="math inline">\(w_{ij}\)</span>, for example,
describes how activity in <span class="math inline">\(x_j\)</span>
changes in response to activity in <span class="math inline">\(x_i\)</span>.</p>
<p>Our goal is to reason about the relationship between underlying
causal structure (which we want to understand) and the correlation or
information shared by pairs of nodes in the circuit (which we can
observe). Quantities based on the adjacency matrix and weighted
reachability matrix bridge this gap, connecting the causal structure of
a circuit to the correlation structure its nodes will produce.</p>
<p>The directional <span class="math inline">\(k^{\mathrm{th}}\)</span>-order connections in the
circuit are similarly described by the matrix <span class="math inline">\(W^k\)</span>, so the <em>weighted reachability
matrix</em> <span class="math display">\[
    \widetilde{W} = \sum_{k=0}^{\infty} W^k
\]</span> describes the total impact &#x2013; through both first-order (direct)
connections and higher-order (indirect) connections &#x2013; of each node on
the others. Whether node <span class="math inline">\(j\)</span> is
&#x201C;reachable&#x201D; (Skiena 2011) from node <span class="math inline">\(i\)</span> by a direct or indirect connection is
thus indicated by <span class="math inline">\(\widetilde{W}_{ij} \neq
0\)</span>, with the magnitude of <span class="math inline">\(\widetilde{W}_{ij}\)</span> indicating sensitive
node <span class="math inline">\(j\)</span> is to a change in node <span class="math inline">\(i\)</span>.</p>
<p>This notion of reachability, encoded by the pattern of nonzero
entries in <span class="math inline">\(\widetilde{W}\)</span>, allows us
to determine when two nodes will be correlated (or more generally,
contain information about each other). Moreover, as we will describe in
Sections [REF] and [REF], quantities derived from these representations
can also be used to describe the impact of open- and closed-loop
interventions on circuit behavior, allowing us to quantitatively explore
the impact of these interventions on the identifiability of
circuits.</p>
<pre class="text language-text" data-role="codeBlock" data-info="text">see also:
@ import &quot;/section_content/background_id_demo.md&quot;</pre>
<h3 id="methods-predict-corr">Predicting correlation structure
(3.1)</h3>
<p>A linear Gaussian circuit can be described by 1) the variance of the
Gaussian private (independent) noise at each node, and 2) the weight of
the linear relationships between each pair of connected nodes. Let <span class="math inline">\(s \in \mathbb{R}^p\)</span> denote the variance of
each of the <span class="math inline">\(p\)</span> nodes in the circuit,
and <span class="math inline">\(W \in \mathbb{R}^{p \times p}\)</span>
denote the matrix of connection strengths such that <span class="math display">\[W_{ij} = \text{strength of $i \to j$
connection}.\]</span></p>
<p>Note that <span class="math inline">\(\left[(W^T) s\right]_j\)</span>
gives the variance at node <span class="math inline">\(j\)</span> due to
length-1 (direct) connections, and more generally, <span class="math inline">\(\left[ (W^T)^k s \right]_j\)</span> gives the
variance at node <span class="math inline">\(j\)</span> due to
length-<span class="math inline">\(k\)</span> (indirect) connections.
The <em>total</em> variance at node <span class="math inline">\(j\)</span> is thus <span class="math inline">\(\left[ \sum_{k=0}^{\infty} (W^T)^k s
\right]_j\)</span>.</p>
<p>Our goal is to connect private variances and connection strengths to
observed pairwise correlations in the circuit. Defining <span class="math inline">\(X \in \mathbb{R}^{p \times n}\)</span> as the
matrix of <span class="math inline">\(n\)</span> observations of each
node, we have<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> <span class="math display">\[
\begin{aligned}
    \Sigma &amp;= \mathrm{cov}(X) = \mathbb{E}\left[X X^T\right] \\
    &amp;= (I-W^T)^{-1} \mathrm{diag}(s) (I-W^T)^{-T} \\
    &amp;= \widetilde{W} \mathrm{diag}(s) \widetilde{W}^T,
\end{aligned}
\]</span> where <span class="math inline">\(\widetilde{W} =
\sum_{k=0}^{\infty} (W)^k\)</span> denotes the <em>weighted reachability
matrix</em>, whose <span class="math inline">\((i,j)^\mathrm{th}\)</span> entry indicates the
total influence of node <span class="math inline">\(i\)</span> on node
<span class="math inline">\(j\)</span> through both direct and indirect
connections.<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a> That is, <span class="math inline">\(\widetilde{W}_{ij}\)</span> tells us how much
variance at node <span class="math inline">\(j\)</span> would result
from injecting a unit of private variance at node <span class="math inline">\(i\)</span>. We can equivalently write <span class="math inline">\(\Sigma_{ij} = \sum_{k=1}^p \widetilde{W}_{ik}
\widetilde{W}_{jk} s_k\)</span>.</p>
<p>Under passive observation, the squared correlation coefficient can
thus be written as <span class="math display">\[
\begin{aligned}
    r^2(i,j) &amp;= \frac{\Sigma_{ij}}{\Sigma_{ii} \Sigma_{jj}} \\
    &amp;= \frac{\left( \sum_{k=1}^p \widetilde{W}_{ik}
\widetilde{W}_{jk} s_k \right)^2}{\left(\sum_{k=1}^p
\widetilde{W}_{ik}^2 s_k\right)\left(\sum_{k=1}^p \widetilde{W}_{jk}^2
s_k\right)}.
\end{aligned}
\]</span></p>
<p>This framework also allows us to predict the impact of open- and
closed-loop control on the pairwise correlations we expect to observe.
To model the application of open-loop control on node <span class="math inline">\(c\)</span>, we add an arbitrary amount of private
variance to <span class="math inline">\(s_c\)</span>: <span class="math inline">\(s_c \leftarrow s_c + s_c^{(OL)}\)</span>. To model
the application of closed-loop control on node <span class="math inline">\(c\)</span>, we first sever inputs to node <span class="math inline">\(c\)</span> by setting <span class="math inline">\(W_{k,c} = 0\)</span> for <span class="math inline">\(k = 1, \dots p\)</span>, and then set the private
variance of node <span class="math inline">\(c\)</span> by setting <span class="math inline">\(s_c\)</span> to any arbitrary value.<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a> Because <span class="math inline">\(c\)</span>&#x2019;s inputs have been severed, this
private noise will become exactly node <span class="math inline">\(c\)</span>&#x2019;s output variance.</p>
<hr>
<p>The impact of intervention on correlations can be understood from the
intervention&#x2019;s location relative to causal circuit connections. One
useful distillation of this concept is to understand the sign of <span class="math inline">\(\frac{dr^2_{ij}}{dS_k}\)</span>, that is whether
increasing the variance of an intervention at node <span class="math inline">\(k\)</span> increases or decreases the correlation
between nodes <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span></p>
<p>In a simulated network A&#x2192;B <a href="#fig-var">(fig.&#xA0;variance)</a> we
demonstrate predicted and emprirical correlations between a pair of
nodes as a function of intervention type, location, and variance. A few
features are present which provide a general intuition for the impact of
intervention location in larger circuits: First, interventions
&#x201C;upstream&#x201D; of a true connection <a href="#fig-var">(lower left,
fig.&#xA0;variance)</a> tend to increase the connection-related variance, and
therefore strengthen the observed correlations.</p>
<p><img src="figures/misc_figure_sketches/quant_r2_prediction_common.png"></p>
<p><code>if:</code> <span class="math display">\[\text{Reach}(S_k&#x2192;i)
\neq 0 \\ \text{Reach}(i&#x2192;j) \neq 0\]</span> <code>then:</code> <span class="math display">\[ \frac{dr^2}{dS_k} &gt; 0\]</span></p>
<p>Second, interventions affecting only the downstream node <a href="#fig-var">(lower right, fig.&#xA0;variance)</a> of a true connection
introduce variance which is independent of the connection A&#x2192;B,
decreasing the observed correlation.</p>
<p><code>if:</code> <span class="math display">\[\text{Reach}(S_k &#x2192; j) =
0 \\ \text{Reach}(S_k &#x2192; j) \neq 0 \]</span> <code>then:</code> <span class="math display">\[ \frac{dr^2}{dS_k} &lt; 0\]</span></p>
<p>Third, interventions which reach both nodes will tend to increase the
observed correlations <a href="#fig-var">(upper left,
fig.&#xA0;variance)</a>, moreover this can be achieved even if no direct
connection <span class="math inline">\(i&#x2192;j\)</span> exists.</p>
<p><code>if:</code> <span class="math display">\[\text{Reach}(S_k &#x2192; i)
\neq 0 \\ \text{Reach}(S_k &#x2192; j) \neq 0 \\ \text{Reach}(i &#x2192; j) = 0
\]</span> <code>then:</code> <span class="math display">\[\frac{dr^2}{dS_k} &gt; 0\]</span></p>
<p>Notably, the impact of an intervention which is a &#x201C;common cause&#x201D; for
both nodes depends on the relative weighted reachability between the
source and each of the nodes. Correlations induced by a common cause are
maximized when the input to each node is equal, that is <span class="math inline">\(\widetilde{W}_{S_k&#x2192;i} \approx
\widetilde{W}_{S_k&#x2192;j}\)</span> (upper right * in <a href="#fig-var">fig.&#xA0;variance</a>). If i&#x2192;j are connected <span class="math inline">\(\widetilde{W}_{S_k&#x2192;i} \gg
\widetilde{W}_{S_k&#x2192;j}\)</span> results in an variance-correlation
relationship similar to the &#x201C;upstream source&#x201D; case (increasing source
variance increases correlation <span class="math inline">\(\frac{dr^2}{dS_k} &gt; 0\)</span>), while <span class="math inline">\(\widetilde{W}_{S_k&#x2192;i} \ll
\widetilde{W}_{S_k&#x2192;j}\)</span> results in a relationship similar to the
&#x201C;downstream source&#x201D; case (<span class="math inline">\(\frac{dr^2}{dS_k}
&lt; 0\)</span>)<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a></p>
<h3 id="impact-of-interventions-theory-pred-31-51">Impact of
interventions - theory, pred (3.1?, 5.1?)</h3>
<hr>
<p><a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a><span class="math display">\[\mathbb{V}_{i}(C|S=\text{open},\sigma^2_S) \geq
\mathbb{V}_{i}(C)\]</span> More specifically, if the open-loop stimulus
is statistically independent from the intrinsic variability<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a> <span class="math display">\[\mathbb{V}_{i}(C|S=\text{open},\sigma^2_S) =
\mathbb{V}_{i}(C) + \sigma^2_S\]</span> Applying closed-loop to a linear
Gaussian circuit:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{V}_{i}(C|S=\text{closed},\sigma^2_S) &amp;= \sigma^2_S  \\
\mathbb{V}_{i}(C|S=\text{closed},\sigma^2_S) &amp;\perp
\mathbb{V}_{i}(C)
\end{aligned}
\]</span></p>
<details>
<summary>
&#x21AA; Firing rates couple mean and variance
</summary>
<p>In neural circuits, we&#x2019;re often interested in firing rates, which are
non-negative. This particular output nonlinearity means that the linear
Gaussian assumptions do not hold, especially in the presence of strong
inhibitory inputs. In this setting, firing rate variability is coupled
to its mean rate; Under a homoeneous-rate Poisson assumption, mean
firing rate and firing rate variability would be proportional. With
inhibitory inputs, open-loop stimulus can drive firing rates low enough
to reduce their variability. Here, feedback control still provides an
advantage in being able to control the mean and variance of firing rates
independently<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a></p>
<p><span class="math display">\[
\begin{aligned}
\mu^{out}_i &amp;= f(\mu^{in}_i, \mathbb{V}^{in}_i)\\
\mathbb{V}^{out}_{i}(C) &amp;= f(\mu^{out}_i, \mathbb{V}^{in}_i)
\end{aligned}
\]</span></p>
</details>
<details>
<summary>
&#x21AA; Notes on imperfect control
</summary>
<code>Ideal control</code> <span class="math display">\[
\mathbb{V}_{i}(C|S=\text{closed},\sigma^2_S) = \sigma^2_S
\]</span> <code>Imperfect control</code> - intuitively feedback control
is counteracting / subtracting disturbance due to unobserved sources,
including intrinsic variability. We could summarize the effectiveness of
closed-loop disturbance rejection with a scalar <span class="math inline">\(0\leq\gamma\leq1\)</span> <span class="math display">\[
\mathbb{V}_{i}(C|S=\text{closed},\sigma^2_S) = \mathbb{V}_{i}(C) -
\gamma\mathbb{V}_{i}(C) + \sigma^2_S \\
\mathbb{V}_{i}(C|S=\text{closed},\sigma^2_S) = (1-\gamma)
\mathbb{V}_{i}(C) + \sigma^2_S
\]</span>
</details>
<pre class="text language-text" data-role="codeBlock" data-info="text">see also:
@ import &quot;/section_content/methods_predicting_correlation.md&quot;
@ import &quot;/section_content/results_impact_of_intervention.md&quot;`</pre>
<h2 id="extracting-circuit-estimates-43">Extracting circuit estimates
(4.3)</h2>
<h2 id="extracting-circuit-estimates">Extracting circuit estimates</h2>
<p>!!!! - 10% done</p>
<blockquote>
<p><em>refer to methods overview figure</em></p>
</blockquote>
<p>While a broad range of techniques<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a> exist for inferring
functional relationships from observational data,
<code>(for the majority of this work)</code> we choose to focus on
simple bivariate correlation as a measure of dependence in the linear
Gaussian network. The impact of intervention on this metric is
analytically tractable <em>(see <a href="methods1_predicting_correlation.md">methods1_predicting_correlation.md</a>)</em>,
and can be thought of as a prototype<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a> for more sophisticated
measures of dependence such as time-lagged cross-correlations, bivariate
and multivariate transfer entropy.</p>
<p>We implement a naive comparison strategy to estimate the circuit
adjacency from emprical correlations; Thresholded empirical correlation
matrices are compared to correlation matrices predicted from each
circuit in a hypothesis set. Any hypothesized cirucits which are
predicted to have a similar correlation structure as is observed
<code>(i.e. corr. mats equal after thresholding)</code> are marked as
&#x201C;plausible circuits.&#x201D;<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a> If only one circuit amongst the
hypothesis set is a plausible match, this is considered to be the
estimated circuit. The threshold for &#x201C;binarizing&#x201D; the empirical
correlation matrix is treated as a hyperparameter to be swept at the
time of analysis.<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a></p>
<h3 id="time-resolvable-interactions-xcorr-412">Time-resolvable
interactions <em>XCORR</em> (4.1.2)</h3>
<p><code>@ import &quot;/section_content/methods_simulations.md&quot; time-resolvable domain</code></p>
<h3 id="sec:entropy">Information-theoretic measures of hypothesis
ambiguity (4.4)</h3>
<p>Shannon entropy provides a scalar summarizing the diversity of a set
of outcomes.. &#x2026;how uniform a discrete probability function is&#x2026; &#x2026;how
surprising&#x2026;(in expectation)</p>
<p><span class="math display">\[H(X) = E[I(X)] = E[\log\frac{1}{p(X)}] =
\sum_{i=1}^{N} p(x_i) \log\frac{1}{p(x_i)} \]</span></p>
<p><code>interpretting high and low entropy</code></p>
<blockquote>
<p>a highly predictable experimental outcome means an experiment where
not much was learned</p>
</blockquote>
<p>An intervention associated with a higher entropy across circuits
will, on average, provide more information to narrow the set of
hypotheses. In fact, one interpretation of entropy is that it describes
the (uncertainty associated with the equivalent) number of
<em>equally-likely</em> outcomes<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a> of a probability mass
function. In this setting <span class="math inline">\(N_{equal}\)</span>
can be thought of as the number of hypotheses that can be distinguished
under a given experiment<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a>. <span class="math display">\[ H(C) = \log_2 N_{equal} \\
N_{equal} = 2^{H(C)}\]</span> For instance, open-loop intervention at
node <span class="math inline">\(x_0\)</span> in <a href="#fig-disambig">(Fig.DISAMBIG right column)</a> results in an
entropy across the hypotheses of <span class="math inline">\(H(C|S_0)
\approx 1.5\)</span>bits or <span class="math inline">\(N_{equal}
\approx 2.8\)</span>. Looking at the patterns of correlation, there are
<span class="math inline">\(N=3\)</span> distinct patterns, with the +++
pattern somewhat more likely than the others (+&#x2013;, 0&#x2013;).<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a>
This intuition also helps understand the maximum entropy achievable for
a given set of hypotheses: <span class="math display">\[H^{max}(C) =
log_2 N\]</span> for this example set: <span class="math display">\[H^{max}(C) = log_2 6 \approx 2.6\]</span></p>
<h3 id="sec:entropy-selection">Selecting interventions (&#x2026;)</h3>
<blockquote>
<p>Evolution of entropy, as the space of hypotheses is narrowed from
experiments and inference.</p>
</blockquote>
<p><span class="math display">\[
\begin{align}
H^{pre}(C):&amp; \text{ uncertainty before intervention (starts at}\,
H^{max}(C))\\
H(C|S_i):&amp; \text{ expected information gain from a given
intervention}\\
H^{post}(C|S_i) = H^{pre} - H(C|S_i):&amp; \text{ expected remaining
uncertainty after intervention}
\end{align}
\]</span> If <span class="math inline">\(H(X|S_i)\approx0 \,\forall
i\)</span>, none of the candidate interventions provide additional
information, and the identification process has converged. If <span class="math inline">\(H^{post} = 0\)</span> the initial hypothesis set
has been reduced down to a single circuit hypothesis consistent with the
observed data<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a>. If <span class="math inline">\(H^{post} &gt; 0\)</span>, some uncertainty remains
in the posterior belief over the hypotheses. In this case a Maximum A
Posteriori (MAP) estimate could be chosen as: <span class="math display">\[ \hat{c}_{\text{MAP}} =
\underset{c}{\text{argmax}} \,L(\text{Corr} | c)\,\pi(c) \]</span> or
the posterior belief can be used as a prior for the next iteration.</p>
<h1 id="references">References</h1>
<p><em>see <a href="https://github.com/shd101wyy/markdown-preview-enhanced/blob/master/docs/pandoc-bibliographies-and-citations.md">pandoc
pandoc-citations</a></em></p>
<h1 class="unnumbered" id="supplement">Supplement</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Adam" class="csl-entry" role="doc-biblioentry">
<span>&#x201C;Adam-to-Do.&#x201D;</span> 2022.
</div>
<div id="ref-ay2008information" class="csl-entry" role="doc-biblioentry">
Ay, Nihat, and Daniel Polani. 2008. <span>&#x201C;Information Flows in Causal
Networks.&#x201D;</span> <em>Advances in Complex Systems</em> 11 (01): 17&#x2013;41.
<a href="https://doi.org/10.1142/S0219525908001465">https://doi.org/10.1142/S0219525908001465</a>.
</div>
<div id="ref-barnett2009granger" class="csl-entry" role="doc-biblioentry">
Barnett, Lionel, Adam B. Barrett, and Anil K. Seth. 2009. <span>&#x201C;Granger
<span>Causality</span> and <span>Transfer Entropy Are Equivalent</span>
for <span>Gaussian Variables</span>.&#x201D;</span> <em>Physical Review
Letters</em> 103 (23): 238701. <a href="https://doi.org/10.1103/PhysRevLett.103.238701">https://doi.org/10.1103/PhysRevLett.103.238701</a>.
</div>
<div id="ref-bossomaier2016transfer" class="csl-entry" role="doc-biblioentry">
Bossomaier, Terry, Lionel Barnett, Michael Harr&#xE9;, and Joseph T. Lizier.
2016. <span>&#x201C;Transfer <span>Entropy</span>.&#x201D;</span> In <em>An
<span>Introduction</span> to <span>Transfer Entropy</span></em>, 65&#x2013;95.
<span>Cham</span>: <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-319-43222-9_4">https://doi.org/10.1007/978-3-319-43222-9_4</a>.
</div>
<div id="ref-chicharro2012when" class="csl-entry" role="doc-biblioentry">
Chicharro, Daniel, and Anders Ledberg. 2012. <span>&#x201C;When <span>Two
Become One</span>: <span>The Limits</span> of <span>Causality
Analysis</span> of <span>Brain Dynamics</span>.&#x201D;</span> Edited by Thomas
Wennekers. <em>PLoS ONE</em> 7 (3): e32466. <a href="https://doi.org/10.1371/journal.pone.0032466">https://doi.org/10.1371/journal.pone.0032466</a>.
</div>
<div id="ref-chis2011structural" class="csl-entry" role="doc-biblioentry">
Chis, Oana-Teodora, Julio R. Banga, and Eva Balsa-Canto. 2011.
<span>&#x201C;Structural <span>Identifiability</span> of <span>Systems Biology
Models</span>: <span>A Critical Comparison</span> of
<span>Methods</span>.&#x201D;</span> Edited by Johannes Jaeger. <em>PLoS
ONE</em> 6 (11): e27755. <a href="https://doi.org/10.1371/journal.pone.0027755">https://doi.org/10.1371/journal.pone.0027755</a>.
</div>
<div id="ref-das2020systematic" class="csl-entry" role="doc-biblioentry">
Das, Abhranil, and Ila R. Fiete. 2020. <span>&#x201C;Systematic Errors in
Connectivity Inferred from Activity in Strongly Recurrent
Networks.&#x201D;</span> <em>Nature Neuroscience</em> 23 (10): 1286&#x2013;96. <a href="https://doi.org/10.1038/s41593-020-0699-2">https://doi.org/10.1038/s41593-020-0699-2</a>.
</div>
<div id="ref-dean2016dangers" class="csl-entry" role="doc-biblioentry">
Dean, Roger T., and William T. M. Dunsmuir. 2016. <span>&#x201C;Dangers and
Uses of Cross-Correlation in Analyzing Time Series in Perception,
Performance, Movement, and Neuroscience: <span>The</span> Importance of
Constructing Transfer Function Autoregressive Models.&#x201D;</span>
<em>Behavior Research Methods</em> 48 (2): 783&#x2013;802. <a href="https://doi.org/10.3758/s13428-015-0611-2">https://doi.org/10.3758/s13428-015-0611-2</a>.
</div>
<div id="ref-eberhardt2007interventions" class="csl-entry" role="doc-biblioentry">
Eberhardt, Frederick, and Richard Scheines. 2007. <span>&#x201C;Interventions
and <span>Causal Inference</span>.&#x201D;</span> <em>Philosophy of
Science</em> 74 (5): 981&#x2013;95. <a href="https://doi.org/10.1086/525638">https://doi.org/10.1086/525638</a>.
</div>
<div id="ref-garofalo2009evaluation" class="csl-entry" role="doc-biblioentry">
Garofalo, Matteo, Thierry Nieus, Paolo Massobrio, and Sergio Martinoia.
2009. <span>&#x201C;Evaluation of the <span>Performance</span> of
<span>Information Theory-Based Methods</span> and
<span>Cross-Correlation</span> to <span>Estimate</span> the
<span>Functional Connectivity</span> in <span>Cortical
Networks</span>.&#x201D;</span> <em>PLOS ONE</em> 4 (8): e6482. <a href="https://doi.org/10.1371/journal.pone.0006482">https://doi.org/10.1371/journal.pone.0006482</a>.
</div>
<div id="ref-ghassami2018budgeted" class="csl-entry" role="doc-biblioentry">
Ghassami, AmirEmad, Saber Salehkaleybar, Negar Kiyavash, and Elias
Bareinboim. 2018. <span>&#x201C;Budgeted Experiment Design for Causal Structure
Learning.&#x201D;</span> In <em>Proc. 35th <span>Int</span>. <span>Conf</span>.
On <span>Machine Learning</span></em>. <span>Stockholm, Sweden</span>.
</div>
<div id="ref-granger1969investigating" class="csl-entry" role="doc-biblioentry">
Granger, C. W. J. 1969. <span>&#x201C;Investigating <span>Causal
Relations</span> by <span>Econometric Models</span> and <span class="nocase">Cross-spectral Methods</span>.&#x201D;</span>
<em>Econometrica</em> 37 (3): 424. <a href="https://doi.org/10.2307/1912791">https://doi.org/10.2307/1912791</a>.
</div>
<div id="ref-janzing2013quantifying" class="csl-entry" role="doc-biblioentry">
Janzing, Dominik, David Balduzzi, Moritz Grosse-Wentrup, and Bernhard
Sch&#xF6;lkopf. 2013. <span>&#x201C;Quantifying Causal Influences.&#x201D;</span> <em>The
Annals of Statistics</em> 41 (5). <a href="https://doi.org/10.1214/13-AOS1145">https://doi.org/10.1214/13-AOS1145</a>.
</div>
<div id="ref-knox1981detection" class="csl-entry" role="doc-biblioentry">
Knox, Charles K. 1981. <span>&#x201C;Detection of Neuronal Interactions Using
Correlation Analysis.&#x201D;</span> <em>Trends in Neurosciences</em> 4
(January): 222&#x2013;25. <a href="https://doi.org/10.1016/0166-2236(81)90070-9">https://doi.org/10.1016/0166-2236(81)90070-9</a>.
</div>
<div id="ref-lizier2010differentiating" class="csl-entry" role="doc-biblioentry">
Lizier, J. T., and M. Prokopenko. 2010. <span>&#x201C;Differentiating
Information Transfer and Causal Effect.&#x201D;</span> <em>The European
Physical Journal B</em> 73 (4): 605&#x2013;15. <a href="https://doi.org/10.1140/epjb/e2010-00034-5">https://doi.org/10.1140/epjb/e2010-00034-5</a>.
</div>
<div id="ref-maathuis2016review" class="csl-entry" role="doc-biblioentry">
Maathuis, Marloes H., and Preetam Nandy. 2016. <span>&#x201C;A Review of Some
Recent Advances in Causal Inference.&#x201D;</span> In <em>Handbook of
<span>Big Data</span></em>, 387&#x2013;408.
</div>
<div id="ref-melssen1987detection" class="csl-entry" role="doc-biblioentry">
Melssen, W. J., and W. J. M. Epping. 1987. <span>&#x201C;Detection and
Estimation of Neural Connectivity Based on Crosscorrelation
Analysis.&#x201D;</span> <em>Biological Cybernetics</em> 57 (6): 403&#x2013;14. <a href="https://doi.org/10.1007/BF00354985">https://doi.org/10.1007/BF00354985</a>.
</div>
<div id="ref-pearl2009causality" class="csl-entry" role="doc-biblioentry">
Pearl, Judea. 2009. <em>Causality: Models, Reasoning, and
Inference</em>. Second. <span>Cambridge University Press</span>.
</div>
<div id="ref-penfield1937somatic" class="csl-entry" role="doc-biblioentry">
Penfield, W., and E. Boldrey. 1937. <span>&#x201C;Somatic Motor and Sensory
Representation in the Cerebral Cortex of Man as Studied by Electrical
Stimulation.&#x201D;</span> <em>Brain: A Journal of Neurology</em> 60: 389&#x2013;443.
<a href="https://doi.org/10.1093/brain/60.4.389">https://doi.org/10.1093/brain/60.4.389</a>.
</div>
<div id="ref-penfield1950cerebral" class="csl-entry" role="doc-biblioentry">
Penfield, Wilder, and Theodore Rasmussen. 1950. <em>The Cerebral Cortex
of Man; a Clinical Study of Localization of Function.</em> The Cerebral
Cortex of Man; a Clinical Study of Localization of Function.
<span>Oxford, England</span>: <span>Macmillan</span>.
</div>
<div id="ref-runge2018causal" class="csl-entry" role="doc-biblioentry">
Runge, J. 2018. <span>&#x201C;Causal Network Reconstruction from Time Series:
<span>From</span> Theoretical Assumptions to Practical
Estimation.&#x201D;</span> <em>Chaos: An Interdisciplinary Journal of Nonlinear
Science</em> 28 (7): 075310. <a href="https://doi.org/10.1063/1.5025050">https://doi.org/10.1063/1.5025050</a>.
</div>
<div id="ref-salinas2001correlated" class="csl-entry" role="doc-biblioentry">
Salinas, Emilio, and Terrence J. Sejnowski. 2001. <span>&#x201C;Correlated
Neuronal Activity and the Flow of Neural Information.&#x201D;</span> <em>Nature
Reviews Neuroscience</em> 2 (8): 539&#x2013;50. <a href="https://doi.org/10.1038/35086012">https://doi.org/10.1038/35086012</a>.
</div>
<div id="ref-schreiber2000measuring" class="csl-entry" role="doc-biblioentry">
Schreiber, Thomas. 2000. <span>&#x201C;Measuring <span>Information
Transfer</span>.&#x201D;</span> <em>Physical Review Letters</em> 85 (2):
461&#x2013;64. <a href="https://doi.org/10.1103/PhysRevLett.85.461">https://doi.org/10.1103/PhysRevLett.85.461</a>.
</div>
<div id="ref-shorten2021estimating" class="csl-entry" role="doc-biblioentry">
Shorten, David P., Richard E. Spinney, and Joseph T. Lizier. 2021.
<span>&#x201C;Estimating <span>Transfer Entropy</span> in <span>Continuous Time
Between Neural Spike Trains</span> or <span>Other Event-Based
Data</span>.&#x201D;</span> <em>PLOS Computational Biology</em> 17 (4):
e1008054. <a href="https://doi.org/10.1371/journal.pcbi.1008054">https://doi.org/10.1371/journal.pcbi.1008054</a>.
</div>
<div id="ref-wibral2014directed" class="csl-entry" role="doc-biblioentry">
Wibral, Michael, Raul Vicente, and Joseph T. Lizier, eds. 2014.
<em>Directed <span>Information Measures</span> in
<span>Neuroscience</span></em>. Understanding <span>Complex
Systems</span>. <span>Berlin, Heidelberg</span>: <span>Springer Berlin
Heidelberg</span>. <a href="https://doi.org/10.1007/978-3-642-54474-3">https://doi.org/10.1007/978-3-642-54474-3</a>.
</div>
<div id="ref-wiener1956theory" class="csl-entry" role="doc-biblioentry">
Wiener, N. 1956. <span>&#x201C;The Theory of Prediction.&#x201D;</span> In <em>Modern
Mathematics for the Engineer</em>. <span>McGraw-Hill</span>.
</div>
<div id="ref-yang2018characterizing" class="csl-entry" role="doc-biblioentry">
Yang, Karren D., Abigail Katoff, and Caroline Uhler. 2018.
<span>&#x201C;Characterizing and Learning Equivalence Classes of Causal
<span>DAGs</span> Under Interventions.&#x201D;</span> In <em>Proc. 35th
<span>Int</span>. <span>Conf</span>. On <span>Machine
Learning</span></em>. <span>Stockholm, Sweden</span>.
</div>
</div>
<section class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>may end up discussing quantitative
advantages such as bidirectional variance (and correlation) control. If
that&#x2019;s a strong focus in the results, should be talked about more in the
abstract also<a href="#fnref1" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn2" role="doc-endnote"><p>TODO: need a more accurate summary of
types of models we look at.<a href="#fnref2" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn3" role="doc-endnote"><p>TODO: need to assess total scope, cut
or diminish reference to time-lagged correlations if it doesn&#x2019;t make it
to final paper<a href="#fnref3" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn4" role="doc-endnote"><p>fill out rest of intervention
caption<a href="#fnref4" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn5" role="doc-endnote"><p>These assumptions are typically on
properties such as the types of functional relationships that exist in
circuits, the visibility and structure of confounding relationships, and
noise statistics.<a href="#fnref5" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn6" role="doc-endnote"><p>if citations needed here, could start
by looking for a good high-level reference in either <span class="citation" data-cites="ghassami2018budgeted">(Ghassami et al.
2018)</span> or <span class="citation" data-cites="yang2018characterizing">(Yang, Katoff, and Uhler
2018)</span>. (Both of these papers are pretty technical, so likely
wouln&#x2019;t be great citations on their own.)<a href="#fnref6" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn7" role="doc-endnote"><p>TODO: make sure this citation is in
the right place)<a href="#fnref7" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn8" role="doc-endnote"><p>saying &#x201C;difficult to distinguish&#x201D;
instead of &#x201C;indistinguishable&#x201D; here since the magnitudes of the
correlations could also be informative with different assumptions<a href="#fnref8" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn9" role="doc-endnote"><p>see <a href="https://www.nature.com/articles/s41593-019-0510-4">Advancing
functional connectivity</a>, fig.&#xA0;2<a href="#fnref9" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn10" role="doc-endnote"><p>more than just an experiment, this
is a &#x201C;hypothesis search.&#x201D; Is this procedure what we&#x2019;re going to brand as
the &#x201C;CLINC&#x201D; process?<a href="#fnref10" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn11" role="doc-endnote"><p>verify whether this is reasonable to
say<a href="#fnref11" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn12" role="doc-endnote"><p>using binary reachability, we can be
more general above predicting the &#x201C;sign/slope&#x201D; (when will they
increase/decrease) of other measures of bivariate dependence like
transfer entropy<a href="#fnref12" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn13" role="doc-endnote"><p>will need to tighten up notation for
intervention summarized as a variable, annotating its type (passive,
open-, closed-loop) as well as its location. Also have to be careful
about overloading <span class="math inline">\(S_i\)</span> as the impact
of private variance and as a particular open-loop intervention<a href="#fnref13" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn14" role="doc-endnote"><p>Omitting several quantitative
practicalities in this step. Notably choosing the amplitude / frequency
content of an intervention w.r.t. estimated parameters of the circuit<a href="#fnref14" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn15" role="doc-endnote"><p>will change the color scheme for
final figure. Likely using orange and blue to denote closed and
open-loop interventions. Will also add in indication of severed edges<a href="#fnref15" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn16" role="doc-endnote"><p>below the level set by added,
independent/&#x201C;private&#x201D; sources<a href="#fnref16" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn17" role="doc-endnote"><p>need a more specific way of stating
this. I mean degrees of freedom in the sense that mean and variance can
be controlled independent of each other. And also, that the range of
achievable correlation coefficients is wider for closed-loop than
open-loop (where intrinsic variability constrains the minimum output
variance)<a href="#fnref17" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn18" role="doc-endnote"><p>compare especially to <a href="https://www.frontiersin.org/articles/10.3389/fncom.2020.00045/full">&#x201C;Transfer
Entropy as a Measure of Brain Connectivity&#x201D;</a>, <a href="https://www.jneurosci.org/content/29/33/10234">&#x201C;How Connectivity,
Background Activity, and Synaptic Properties Shape the Cross-Correlation
between Spike Trains&#x201D;</a> Figure 3.<a href="#fnref18" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn19" role="doc-endnote"><p>this corroborates Ila Fiete&#x2019;s paper
on bias as a function of recurrent network strength<a href="#fnref19" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn20" role="doc-endnote"><p>However, depending on overall firing
rates and population sizes, this sparse spike-based transmission can be
coarse-grained to a firing-rate-based model.<a href="#fnref20" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn21" role="doc-endnote"><p>cases doesnt work with pandoc yet,
also want to talk about positive and negative lags here<a href="#fnref21" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn22" role="doc-endnote"><p>the effective <span class="math inline">\(\Delta_{sample}\)</span> would be broadened in the
presence of jitter in connection delay, measurement noise, or temporal
smoothing applied post-hoc, leading<a href="#fnref22" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn23" role="doc-endnote"><p>need to triple check indexing w.r.t.
nodes, neurons<a href="#fnref23" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn24" role="doc-endnote"><p>need to resolve differences in
implementation between contemporaneous and voltage simulation cases<a href="#fnref24" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn25" role="doc-endnote"><p>NEED dynamic clamp refs -
http://www.scholarpedia.org/article/Dynamic_clamp<a href="#fnref25" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn26" role="doc-endnote"><p>the most important property of <span class="math inline">\(e\)</span> for the math to work, i believe, is
that they&#x2019;re random variables independent of each other. This is not
true in general if E is capturing input from common sources, other nodes
in the network. I think to solve this, we&#x2019;ll need to have an endogenous
independent noise term and an externally applied (potentially common)
stimulus term.<a href="#fnref26" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn27" role="doc-endnote"><p>have to be careful with this. this
almost looks like a dynamical system, but isn&#x2019;t. In simulation we&#x2019;re
doing something like an SCM, where the circuit is sorted topologically
then computed sequentially. have to resolve / compare these
implementations<a href="#fnref27" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn28" role="doc-endnote"><p>To see this, denote by <span class="math inline">\(E \in \mathbb{R}^{p \times n}\)</span> the matrix
of <span class="math inline">\(n\)</span> private noise observations for
each node. Note that <span class="math inline">\(X = W^T X + E\)</span>,
so <span class="math inline">\(X = E(I-W^T)^{-1}\)</span>. The
covariance matrix <span class="math inline">\(\Sigma = \mathrm{cov}(X) =
\mathbb{E}\left[X X^T\right]\)</span> can then be written as <span class="math inline">\(\Sigma = \mathbb{E}\left[ (I-W^T)^{-1} E E^T
(I-W^T)^{-1} \right] = (I-W^T)^{-1} \mathrm{cov}(E) (I-W^T)^{-T} =
(I-W^T)^{-1} \mathrm{diag}(s) (I-W^T)^{-T}\)</span>.<a href="#fnref28" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn29" role="doc-endnote"><p>We can use <span class="math inline">\(p-1\)</span> as an upper limit on the sum <span class="math inline">\(\widetilde{W} = \sum_{k=0}^{\infty} W^k\)</span>
when there are no recurrent connections.<a href="#fnref29" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn30" role="doc-endnote"><p>TODO: to any target value?<a href="#fnref30" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn31" role="doc-endnote"><p>TODO: verify not 100% sure this is
true, the empirical results are really pointing to dr^2/dW&lt;0 rather
than dr^2/dS&lt;0. Also this should really be something like <span class="math inline">\(\frac{d|R|}{dS}\)</span> or <span class="math inline">\(\frac{dr^2}{dS}\)</span> since these effects
decrease the <em>magnitude</em> of correlations. I.e. if <span class="math inline">\(\frac{d|R|}{dS} &lt; 0\)</span> increasing <span class="math inline">\(S\)</span> might move <span class="math inline">\(r\)</span> from <span class="math inline">\(-0.8\)</span> to <span class="math inline">\(-0.2\)</span>, i.e.&#xA0;decrease its magnitude not its
value.<a href="#fnref31" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn32" role="doc-endnote"><p>need to be clear V means variance<a href="#fnref32" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn33" role="doc-endnote"><p>notably, this is part of the
definition of open-loop intervention<a href="#fnref33" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn34" role="doc-endnote"><p>practically, this requires very fast
feedback to achieve fully independent control over mean and variance. In
the case of firing rates, I suspect <span class="math inline">\(\mu \leq
\alpha\mathbb{V}\)</span>, so variances can be reduced, but for very low
firing rates, there&#x2019;s still an upper limit on what the variance can
be.<a href="#fnref34" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn35" role="doc-endnote"><p><em>inference techniques mentioned
in the intro&#x2026;</em><a href="#fnref35" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn36" role="doc-endnote"><p>what does &#x201C;prototype&#x201D; mean here?
something like MI and corr are equivalent in the linear Gaussian case,
&#x2026;<a href="#fnref36" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn37" role="doc-endnote"><p>TODO? formalize notation for this<a href="#fnref37" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn38" role="doc-endnote"><p>not sure how important this is.
would prefer to set this threshold at some ad-hoc value since we&#x2019;re
sweeping other properties. But a more in-depth analysis could look at a
receiver-operator curve with respect to this threshold<a href="#fnref38" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn39" role="doc-endnote"><p>i.e.&#xA0;if you took a PMF and counted
the number of categories with probability greater than <span class="math inline">\(p_th\)</span>. A distribution with 16 possible
outcomes, but only 2bits of uncertainty is <em>as</em> uncertain as a
uniform distribution with <span class="math inline">\(2^2\)</span>
equally likely outcomes<a href="#fnref39" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn40" role="doc-endnote"><p>connect this section to the idea of
the markdov equivalence class, and its size<a href="#fnref40" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn41" role="doc-endnote"><p>since <span class="math inline">\(H(C)\leq H^{max}(C)\)</span>, <span class="math inline">\(N_{equal} \leq N\)</span><a href="#fnref41" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
<li id="fn42" role="doc-endnote"><p>what about the scenario where the
ground truth circuit is not in the hypotheses set?<a href="#fnref42" class="footnote-back" role="doc-backlink">&#x21A9;&#xFE0E;</a></p></li>
</ol>
</section>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>