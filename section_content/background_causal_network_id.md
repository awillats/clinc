**Estimating causal interactions in the brain.** Many hypotheses about neural circuits are best stated in terms of causal relationships: "changes made in to activity in this region of the brain will produce corresponding changes in that downstream region." Understanding these causal relationships is critical to developing effective therapeutic interventions, which require knowledge of how potential therapies will change brain activity and patient outcomes.

A range of mathematical and practical challenges make it difficult to determine these causal relationships. In studies that rely only observational data, it is often impossible to determine whether observed patterns of activity are due to known and controlled inputs, or whether they are caused by recurrent activity, indirect relationships, or unseen "confounders." The chemical and surgical lesion experiments that have historically been employed to remove the influence of possible confounds are likely to dramatically disrupt circuits from their typical functions, making conclusions about underlying causal structure drawn from these experiments unlikely to hold in naturalistic settings \cite{chicharro2012when}.

In this paper we demonstrate when and how *closed-loop interventions* can reveal the causal structure governing neural circuits. It is generally understood that moving from experiments involving passive observation to more complex levels of intervention allows experimenters to better tackle challenges to circuit identification. However, it is not yet fully understood when more complex intervention strategies can provide additional inferential power or how these interventions should be designed. To meet this need, we draw from tools used in causal inference \cite{pearl2009causality} \cite{maathuis2016review} \cite{chis2011structural}, which answer questions about what classes of models can be distinguished under a given set of input output experiments, and what experiments are necessary to determine internal connections uniquely.

We first propose a mathematical framework that describes how open- and closed-loop interventions impact the observable qualities of neural circuits. Using both simple controlled models and in silico models of neural circuits, we explore factors that govern the efficacy of these types of interventions. Guided by the results of this exploration, we present a set of recommendations that can guide the design of open- and closed-loop experiments that can better uncover the connections which underly neural circuit function.

**Inferring causal interactions from time series.** A number of measures have been proposed to quantify the strength of interaction between variables. Wiener-Granger (or predictive) causality states that a variable $X$ *Granger-causes* $Y$ if $X$ contains information relevant to $Y$ that is not contained in $Y$ itself or any other variable \cite{wiener1956theory}, a concept that has traditionally been operationalized with vector autoregressive models \cite{granger1969investigating}. The requirement that *all* potentially causative variables be considered makes these notions of dependence susceptible to unobserved confounders \cite{??}.

Our work initially focuses on measures of directional interaction that are based on cross-correlation. These metrics look at the correlation of time series collected from two nodes at various lags, treating peaks at negative time lags as evidence for potential causative relationships (which may stem from either direct causal interaction, indirect causal interaction, or a common cause). While cross-correlation-based measures are generally limited to detecting linear functional relationships between nodes, it is computationally inexpensive, making it a metric of choice for many real-world problems. ==More about correlation-based measures.==

Other metrics quantify directional interaction stemming from more general or complex relationships. Information-theoretic methods, which use information-based measures to assess the reduction in entropy knowledge of one variable provides about another, are closely related to Granger causality \cite{schreiber2000measuring} \cite{barnett2009granger}. The *transfer entropy* $T_{X \to Y}(t) = I(Y_t \colon X_{<t} \mid Y_{<t})$ extends this notion to time series by measuring the amount of information present in $Y_t$ that is not contained in the past of either $X$ or $Y$ (denoted $X_{<t}$ and $Y_{<t}$) \cite{bossomaier2016transfer}. Using transfer entropy as a measure of causal interaction requires accounting for potential confounding variables; the *conditional transfer entropy* $T_{X \to Y \mid Z}(t) = I(Y_t \colon X_{<t} \mid Y_{<t}, Z_{<t})$ conditions on the past of other variables to account for their confounding influence \cite[Sec.~4.2.3]{bossomaier2016transfer}. Conditional transfer entropy can thus be interpreted as the amount of information present in $Y$ that is not present in either the past of $X$, the past of $Y$, or the past of other variables $Z$.

Information-theoretic and transfer-entropy-based methods used to quantify the strength of causal interactions typically require knowledge of the ground truth causal relationships that exist \cite{janzing2013quantifying} or the ability to perturb the system \cite{ay2008information} \cite{lizier2010differentiating}. In practice, these quantities are often interpreted as "information transfer," and a variety of estimation strategies and methods to automatically select variables and time lags to condition are used (e.g., \cite{shorten2021estimating). Multivariate conditional transfer entropy approaches using various variable selection schemes can differentiate between direct interactions, indirect interactions, and common causes. The results from these methods can often differ based on binning strategies used to discretize continuous signals, the specific statistical tests used, and the estimator used to compute transfer entropy. In our empirical results using transfer-entropy-based notions of directional influence we use the IDTxl toolbox \cite{wollstadt2019idtxl}.

==GC in neuro [@Adam]==

!!!!! note todo - skim through these papers for methods/material to cite

- reviews to read/cite:
    - specific to neuro
        - \cite{TODO-chicharro2012when}
        - \cite{TODO-dean2016dangers}
        - \cite{TODO-garofalo2009evaluation}
        - \cite{TODO-knox1981detection
        - \cite{TODO-salinas2001correlated}
        - \cite{TODO-wibral2014directed}
    - maybe...
        - \cite{TODO-lacasa2015network}
        - \cite{TODO-melssen1987detection}
- see `sketches_and_notation/background_why_control.md`
