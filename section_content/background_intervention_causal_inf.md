Data collected from experimental settings can provide more inferential power than observational data alone. For example, consider an experimentalist who is considering multiple causal hypotheses for two nodes under study, $x$ and $y$: the hypothesis that $x$ is driving $y$, the hypothesis that $y$ is driving $x$, or the hypothesis that the two variables are being independently driven by a hidden confounder. Observational data revealing that $x$ and $y$ produce correlated time-series data is equally consistent with each of these three causal hypotheses, providing the experimentalist with no inferential power. Experimentally manipulating $x$ and observing the output of $y$, however, allows the scientist to begin to establish which causal interaction pattern is at work. Consistent with intuition from neuroscience literature, a rich theoretical literature has described the central role of interventions in inferring causal structure from data \cite{pearl2009causality, eberhardt2007interventions}.

![](/figures/core_figure_sketches/figure1_sketch.png "")
> **Figure INTRO:** Examples of the roles interventions have played in neuroscience. (A) *Passive observation* does not involve stimulating the brain. In this example, passive observational data is used to identify patients suffering from absence seizures. (B) *Open-loop stimulation* involves recording activity in the brain after perturbing a region with a known input signal. Using systematic *open-loop stimulation experiments*, Penfield uncovered the spatial organization of how senses and movement are mapped in the cortex \cite{penfield1937somatic} \cite{penfield1950cerebral}. (C) *Closed-loop control* uses feedback control to precisely specify activity in certain brain regions regardless of activity in other regions. Using closed-loop control, ==todo-Adam== \cite{==todo-Adam==}.

The inferential power of interventions is depends on *where* stimulation is applied: interventions on some portions of a system may provide more information about the system's causal structure than interventions in other areas. And interventions are also more valuable when they more effectively set the state of the system: "perfect" closed-loop control, which completely severs a node's activity from its inputs, are often more informative than "soft" interventions that only partially control a part of the system \cite{eberhardt2007interventions}.

In experimental neuroscience settings, experimenters are faced with deciding between interventions that differ in both location and effectiveness. For example, stimulation can often only be applied to certain regions of the brain. And while experimenters may be able to exactly manipulate activity in some parts of the brain using closed-loop control, in other locations it may only be possible to apply weaker forms of intervention that perturb a region but do not manipulate its activity exactly to a desired state. In Section [X], we compare the effectiveness of open-loop, closed-loop, and partially-effective closed-loop control.

Although algorithms designed to choose optimal interventions are often designed for simple models with strong assumptions,[^more] they provide intuition that can aid practitioners seeking to design real-world experiments that provide as much scientific insight as possible.[^possible-cite] Importantly, the informativeness of interventions is often independent of the algorithm used to infer causal connections, meaning that certain interventions can reveal portions of a circuit's causal structure that would be impossible for *any* algorithm to infer from only observational data \cite{das2020systematic} ==(<- Matt to Adam: make sure this citation is in the right place)==. We similarly expect the results we demonstrate in this paper to both inform experimentalists and open avenues for further research.

[^more]: These assumptions are typically on properties such as the types of functional relationships that exist in circuits, the visibility and structure of confounding relationships, and noise statistics.

[^possible-cite]: if citations needed here, could start by looking for a good high-level reference in either \cite{ghassami2018budgeted} or \cite{yang2018characterizing}. (Both of these papers are pretty technical, so likely wouln't be great citations on their own.)
